{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f678e4adfb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(62)\n",
    "torch.manual_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi vocab_size: 20402\n"
     ]
    }
   ],
   "source": [
    "# load HINDI mapping {word -> id} and {id -> word}\n",
    "with open('../Task_1/save/word_to_int_dict.json') as f:\n",
    "    hindi_word_to_int = json.load(f)\n",
    "with open('../Task_1/save/int_to_word_dict.json') as f:\n",
    "    hindi_int_to_word = json.load(f)\n",
    "\n",
    "# get vocab_size\n",
    "hindi_vocab_size = len(hindi_word_to_int)\n",
    "print(f'hindi vocab_size: {hindi_vocab_size}')\n",
    "\n",
    "# load embedding\n",
    "hindi_embedding_path = '../Task_1/save/embedding_weights.pt'\n",
    "hindi_embed_layer = nn.Embedding(hindi_vocab_size, embedding_size)\n",
    "hindi_embed_layer.load_state_dict(torch.load(hindi_embedding_path, map_location=torch.device(device)))\n",
    "hindi_embed_matrix = hindi_embed_layer.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengali vocab_size: 16005\n"
     ]
    }
   ],
   "source": [
    "# load BENGALI mapping {word -> id} and {id -> word}\n",
    "with open('hindi_bengali/save/word_to_int_dict.json') as f:\n",
    "    bengali_word_to_int = json.load(f)\n",
    "with open('hindi_bengali/save/int_to_word_dict.json') as f:\n",
    "    bengali_int_to_word = json.load(f)\n",
    "\n",
    "# get vocab_size\n",
    "bengali_vocab_size = len(bengali_word_to_int)\n",
    "print(f'bengali vocab_size: {bengali_vocab_size}')\n",
    "\n",
    "# load embedding\n",
    "bengali_embedding_path = '../Task_2/hindi_bengali/save/embedding_weights.pt'\n",
    "bengali_embed_layer = nn.Embedding(bengali_vocab_size, embedding_size)\n",
    "bengali_embed_layer.load_state_dict(torch.load(bengali_embedding_path, map_location=torch.device(device)))\n",
    "bengali_embed_matrix = bengali_embed_layer.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(v):\n",
    "    return v.sub_(v.mean(dim=1)[:, None]).div_((v.var(dim=1)**0.5)[:, None])\n",
    "\n",
    "hindi_embed_matrix = standardize(hindi_embed_matrix)\n",
    "bengali_embed_matrix = standardize(bengali_embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize embedding matrices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [ #(hindi_word, bengali_word, english word)\n",
    "    ('गाड़ी', 'গাড়ি', 'car'),\n",
    "    ('विश्व', 'বিশ্ব', 'world'),\n",
    "    ('शब्द', 'শব্দ', 'word'),\n",
    "    ('संगणक', 'কম্পিউটার', 'computer'),\n",
    "    ('लोग', 'মানুষ', 'people'),\n",
    "    ('युद्ध', 'যুদ্ধ', 'war'),\n",
    "    ('फ़ोन', 'ফোন', 'phone'),\n",
    "    ('होशियार', 'স্মার্ট', 'smart'),\n",
    "    ('सुंदर', 'সুন্দর', 'beautiful'),\n",
    "    ('तेज', 'দ্রুত', 'fast'),\n",
    "    #('', ''), # \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "गाड़ी গাড়ি car\n",
      "1401 12996\n",
      "विश्व বিশ্ব world\n",
      "12982 8447\n",
      "शब्द শব্দ word\n",
      "8654 14377\n",
      "लोग মানুষ people\n",
      "12398 19582\n",
      "युद्ध যুদ্ধ war\n",
      "12632 11059\n",
      "फ़ोन ফোন phone\n",
      "895 6872\n",
      "सुंदर সুন্দর beautiful\n",
      "6050 9795\n",
      "तेज দ্রুত fast\n",
      "12512 5323\n"
     ]
    }
   ],
   "source": [
    "for hindi_word, bengali_word, english_word in examples:\n",
    "    if hindi_word in hindi_word_to_int and bengali_word in bengali_word_to_int:\n",
    "        print(hindi_word, bengali_word, english_word)\n",
    "        hindi_id = hindi_word_to_int[hindi_word]\n",
    "        bengali_id = bengali_word_to_int[bengali_word]\n",
    "        \n",
    "        ben_ranking = torch.argsort(bengali_embed_matrix@hindi_embed_matrix[hindi_id], descending=True)\n",
    "        hin_ranking = torch.argsort(hindi_embed_matrix@bengali_embed_matrix[bengali_id], descending=True)\n",
    "        \n",
    "        print(f'{ben_ranking[bengali_id]} {hin_ranking[hindi_id]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
