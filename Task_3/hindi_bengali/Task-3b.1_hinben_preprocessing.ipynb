{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Sample Bengali dataset and do preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(62)\n",
    "torch.manual_seed(2021)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Bengali datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample Bengali datasets\n",
    "bengali_train_df = pd.read_csv('../../Task_2/hindi_bengali/save/bengali_hatespeech_sample_train.csv')\n",
    "bengali_test_df = pd.read_csv('../../Task_2/hindi_bengali/save/bengali_hatespeech_sample_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = bengali_train_df['sentence']\n",
    "test_sentences = bengali_test_df['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove user taggings\n",
    "user_tag_pattern = re.compile(r'\\@\\w*')\n",
    "def remove_tagging(sentence):\n",
    "    return re.sub(user_tag_pattern, ' ', sentence)\n",
    "\n",
    "# remove punctuations and urls\n",
    "http_re = re.compile('http://[^ ]*')\n",
    "https_re = re.compile('https://[^ ]*')\n",
    "punctuation = string.punctuation[:2] + string.punctuation[3:]\n",
    "translator = str.maketrans(punctuation, ' '*len(punctuation))\n",
    "def remove_punc_and_urls(s):\n",
    "    s = re.sub(http_re, ' ', s)\n",
    "    s = re.sub(https_re, ' ', s)\n",
    "    s = s.translate(translator)\n",
    "    return s\n",
    "\n",
    "# substitute numbers\n",
    "#   when there is a number in the string:\n",
    "#   if that number is 0 or 1 or 2, then there is no change.\n",
    "#   else, that number is substituted by a word describing how many digits it has.\n",
    "def substitute_number(x):\n",
    "    x = x.group(0)\n",
    "    if x in {'0', '1', '2'}:\n",
    "        return x\n",
    "    return '{}_digits_number'.format(len(x))\n",
    "\n",
    "# stopwords BENGALI (source: https://www.ranks.nl/stopwords/bengali)\n",
    "stopwords = ['‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø', '‡¶Ö‡¶®‡ßá‡¶ï', '‡¶Ö‡¶®‡ßá‡¶ï‡ßá', '‡¶Ö‡¶®‡ßá‡¶ï‡ßá‡¶á', '‡¶Ö‡¶®‡ßç‡¶§‡¶§', '‡¶Ö‡¶•‡¶¨‡¶æ', '‡¶Ö‡¶•‡¶ö', '‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡¶§', '‡¶Ö‡¶®‡ßç‡¶Ø', '‡¶Ü‡¶ú', '‡¶Ü‡¶õ‡ßá', '‡¶Ü‡¶™‡¶®‡¶æ‡¶∞', \n",
    "             '‡¶Ü‡¶™‡¶®‡¶ø', '‡¶Ü‡¶¨‡¶æ‡¶∞', '‡¶Ü‡¶Æ‡¶∞‡¶æ', '‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá', '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞', '‡¶Ü‡¶Æ‡¶æ‡¶∞', '‡¶Ü‡¶Æ‡¶ø', '‡¶Ü‡¶∞‡¶ì', '‡¶Ü‡¶∞', '‡¶Ü‡¶ó‡ßá', '‡¶Ü‡¶ó‡ßá‡¶á', '‡¶Ü‡¶á', \n",
    "             '‡¶Ö‡¶§‡¶è‡¶¨', '‡¶Ü‡¶ó‡¶æ‡¶Æ‡ßÄ', '‡¶Ö‡¶¨‡¶ß‡¶ø', '‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ', '‡¶Ü‡¶¶‡ßç‡¶Ø‡¶≠‡¶æ‡¶ó‡ßá', '‡¶è‡¶á', '‡¶è‡¶ï‡¶á', '‡¶è‡¶ï‡ßá', '‡¶è‡¶ï‡¶ü‡¶ø', '‡¶è‡¶ñ‡¶®', '‡¶è‡¶ñ‡¶®‡¶ì', '‡¶è‡¶ñ‡¶æ‡¶®‡ßá', \n",
    "             '‡¶è‡¶ñ‡¶æ‡¶®‡ßá‡¶á', '‡¶è‡¶ü‡¶ø', '‡¶è‡¶ü‡¶æ', '‡¶è‡¶ü‡¶æ‡¶á', '‡¶è‡¶§‡¶ü‡¶æ‡¶á', '‡¶è‡¶¨‡¶Ç', '‡¶è‡¶ï‡¶¨‡¶æ‡¶∞', '‡¶è‡¶¨‡¶æ‡¶∞', '‡¶è‡¶¶‡ßá‡¶∞', '‡¶è‡¶Å‡¶¶‡ßá‡¶∞', '‡¶è‡¶Æ‡¶®', '‡¶è‡¶Æ‡¶®‡¶ï‡ßÄ', '‡¶è‡¶≤', \n",
    "             '‡¶è‡¶∞', '‡¶è‡¶∞‡¶æ', '‡¶è‡¶Å‡¶∞‡¶æ', '‡¶è‡¶∏', '‡¶è‡¶§', '‡¶è‡¶§‡ßá', '‡¶è‡¶∏‡ßá', '‡¶è‡¶ï‡ßá', '‡¶è', '‡¶ê', ' ‡¶á', '‡¶á‡¶π‡¶æ', '‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø', '‡¶â‡¶®‡¶ø', '‡¶â‡¶™‡¶∞', \n",
    "             '‡¶â‡¶™‡¶∞‡ßá', '‡¶â‡¶ö‡¶ø‡¶§', '‡¶ì', '‡¶ì‡¶á', '‡¶ì‡¶∞', '‡¶ì‡¶∞‡¶æ', '‡¶ì‡¶Å‡¶∞', '‡¶ì‡¶Å‡¶∞‡¶æ', '‡¶ì‡¶ï‡ßá', '‡¶ì‡¶¶‡ßá‡¶∞', '‡¶ì‡¶Å‡¶¶‡ßá‡¶∞', '‡¶ì‡¶ñ‡¶æ‡¶®‡ßá', '‡¶ï‡¶§', '‡¶ï‡¶¨‡ßá', \n",
    "             '‡¶ï‡¶∞‡¶§‡ßá', '‡¶ï‡ßü‡ßá‡¶ï', '‡¶ï‡ßü‡ßá‡¶ï‡¶ü‡¶ø', '‡¶ï‡¶∞‡¶¨‡ßá', '‡¶ï‡¶∞‡¶≤‡ßá‡¶®', '‡¶ï‡¶∞‡¶æ‡¶∞', '‡¶ï‡¶æ‡¶∞‡¶ì', '‡¶ï‡¶∞‡¶æ', '‡¶ï‡¶∞‡¶ø', '‡¶ï‡¶∞‡¶ø‡ßü‡ßá', '‡¶ï‡¶∞‡¶æ‡¶∞', '‡¶ï‡¶∞‡¶æ‡¶á', \n",
    "             '‡¶ï‡¶∞‡¶≤‡ßá', '‡¶ï‡¶∞‡¶≤‡ßá‡¶®', '‡¶ï‡¶∞‡¶ø‡¶§‡ßá', '‡¶ï‡¶∞‡¶ø‡ßü‡¶æ', '‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡¶≤‡ßá‡¶®', '‡¶ï‡¶∞‡¶õ‡ßá', '‡¶ï‡¶∞‡¶õ‡ßá‡¶®', '‡¶ï‡¶∞‡ßá‡¶õ‡ßá‡¶®', '‡¶ï‡¶∞‡ßá‡¶õ‡ßá', '‡¶ï‡¶∞‡ßá‡¶®', '‡¶ï‡¶∞‡¶¨‡ßá‡¶®', \n",
    "             '‡¶ï‡¶∞‡¶æ‡ßü', '‡¶ï‡¶∞‡ßá', '‡¶ï‡¶∞‡ßá‡¶á', '‡¶ï‡¶æ‡¶õ', '‡¶ï‡¶æ‡¶õ‡ßá', '‡¶ï‡¶æ‡¶ú‡ßá', '‡¶ï‡¶æ‡¶∞‡¶£', '‡¶ï‡¶ø‡¶õ‡ßÅ', '‡¶ï‡¶ø‡¶õ‡ßÅ‡¶á', '‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ', '‡¶ï‡¶ø‡¶Ç‡¶¨‡¶æ', '‡¶ï‡¶ø', '‡¶ï‡ßÄ', '‡¶ï‡ßá‡¶â', \n",
    "             '‡¶ï‡ßá‡¶â‡¶á', '‡¶ï‡¶æ‡¶â‡¶ï‡ßá', '‡¶ï‡ßá‡¶®', '‡¶ï‡ßá', '‡¶ï‡ßã‡¶®‡¶ì', '‡¶ï‡ßã‡¶®‡ßã', '‡¶ï‡ßã‡¶®', '‡¶ï‡¶ñ‡¶®‡¶ì', '‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá', '‡¶ñ‡ßÅ‡¶¨\t‡¶ó‡ßÅ‡¶≤‡¶ø', '‡¶ó‡¶ø‡ßü‡ßá', '‡¶ó‡¶ø‡ßü‡ßá‡¶õ‡ßá', \n",
    "             '‡¶ó‡ßá‡¶õ‡ßá', '‡¶ó‡ßá‡¶≤', '‡¶ó‡ßá‡¶≤‡ßá', '‡¶ó‡ßã‡¶ü‡¶æ', '‡¶ö‡¶≤‡ßá', '‡¶õ‡¶æ‡ßú‡¶æ', '‡¶õ‡¶æ‡ßú‡¶æ‡¶ì', '‡¶õ‡¶ø‡¶≤‡ßá‡¶®', '‡¶õ‡¶ø‡¶≤', '‡¶ú‡¶®‡ßç‡¶Ø', '‡¶ú‡¶æ‡¶®‡¶æ', '‡¶†‡¶ø‡¶ï', '‡¶§‡¶ø‡¶®‡¶ø', \n",
    "             '‡¶§‡¶ø‡¶®‡¶ê', '‡¶§‡¶ø‡¶®‡¶ø‡¶ì', '‡¶§‡¶ñ‡¶®', '‡¶§‡¶¨‡ßá', '‡¶§‡¶¨‡ßÅ', '‡¶§‡¶æ‡¶Å‡¶¶‡ßá‡¶∞', '‡¶§‡¶æ‡¶Å‡¶æ‡¶π‡¶æ‡¶∞‡¶æ', '‡¶§‡¶æ‡¶Å‡¶∞‡¶æ', '‡¶§‡¶æ‡¶Å‡¶∞', '‡¶§‡¶æ‡¶Å‡¶ï‡ßá', '‡¶§‡¶æ‡¶á', '‡¶§‡ßá‡¶Æ‡¶®', '‡¶§‡¶æ‡¶ï‡ßá', \n",
    "             '‡¶§‡¶æ‡¶π‡¶æ', '‡¶§‡¶æ‡¶π‡¶æ‡¶§‡ßá', '‡¶§‡¶æ‡¶π‡¶æ‡¶∞', '‡¶§‡¶æ‡¶¶‡ßá‡¶∞', '‡¶§‡¶æ‡¶∞‡¶™‡¶∞', '‡¶§‡¶æ‡¶∞‡¶æ', '‡¶§‡¶æ‡¶∞‡ßà', '‡¶§‡¶æ‡¶∞', '‡¶§‡¶æ‡¶π‡¶≤‡ßá', '‡¶§‡¶ø‡¶®‡¶ø', '‡¶§‡¶æ', '‡¶§‡¶æ‡¶ì', '‡¶§‡¶æ‡¶§‡ßá', \n",
    "             '‡¶§‡ßã', '‡¶§‡¶§', '‡¶§‡ßÅ‡¶Æ‡¶ø', '‡¶§‡ßã‡¶Æ‡¶æ‡¶∞', '‡¶§‡¶•‡¶æ', '‡¶•‡¶æ‡¶ï‡ßá', '‡¶•‡¶æ‡¶ï‡¶æ', '‡¶•‡¶æ‡¶ï‡¶æ‡ßü', '‡¶•‡ßá‡¶ï‡ßá', '‡¶•‡ßá‡¶ï‡ßá‡¶ì', '‡¶•‡¶æ‡¶ï‡¶¨‡ßá', '‡¶•‡¶æ‡¶ï‡ßá‡¶®', '‡¶•‡¶æ‡¶ï‡¶¨‡ßá‡¶®', \n",
    "             '‡¶•‡ßá‡¶ï‡ßá‡¶á', '‡¶¶‡¶ø‡¶ï‡ßá', '‡¶¶‡¶ø‡¶§‡ßá', '‡¶¶‡¶ø‡ßü‡ßá', '‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá', '‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá‡¶®', '‡¶¶‡¶ø‡¶≤‡ßá‡¶®', '‡¶¶‡ßÅ', '‡¶¶‡ßÅ‡¶ü‡¶ø', '‡¶¶‡ßÅ‡¶ü‡ßã', '‡¶¶‡ßá‡ßü', '‡¶¶‡ßá‡¶ì‡ßü‡¶æ', '‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞', \n",
    "             '‡¶¶‡ßá‡¶ñ‡¶æ', '‡¶¶‡ßá‡¶ñ‡ßá', '‡¶¶‡ßá‡¶ñ‡¶§‡ßá', '‡¶¶‡ßç‡¶¨‡¶æ‡¶∞‡¶æ', '‡¶ß‡¶∞‡ßá', '‡¶ß‡¶∞‡¶æ', '‡¶®‡ßü', '‡¶®‡¶æ‡¶®‡¶æ', '‡¶®‡¶æ', '‡¶®‡¶æ‡¶ï‡¶ø', '‡¶®‡¶æ‡¶ó‡¶æ‡¶¶', '‡¶®‡¶ø‡¶§‡ßá', '‡¶®‡¶ø‡¶ú‡ßá', '‡¶®‡¶ø‡¶ú‡ßá‡¶á', \n",
    "             '‡¶®‡¶ø‡¶ú‡ßá‡¶∞', '‡¶®‡¶ø‡¶ú‡ßá‡¶¶‡ßá‡¶∞', '‡¶®‡¶ø‡ßü‡ßá', '‡¶®‡ßá‡¶ì‡ßü‡¶æ', '‡¶®‡ßá‡¶ì‡ßü‡¶æ‡¶∞', '‡¶®‡ßá‡¶á', '‡¶®‡¶æ‡¶á', '‡¶™‡¶ï‡ßç‡¶∑‡ßá', '‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§', '‡¶™‡¶æ‡¶ì‡ßü‡¶æ', '‡¶™‡¶æ‡¶∞‡ßá‡¶®', '‡¶™‡¶æ‡¶∞‡¶ø', '‡¶™‡¶æ‡¶∞‡ßá', \n",
    "             '‡¶™‡¶∞‡ßá', '‡¶™‡¶∞‡ßá‡¶á', '‡¶™‡¶∞‡ßá‡¶ì', '‡¶™‡¶∞', '‡¶™‡ßá‡ßü‡ßá', '‡¶™‡ßç‡¶∞‡¶§‡¶ø', '‡¶™‡ßç‡¶∞‡¶≠‡ßÉ‡¶§‡¶ø', '‡¶™‡ßç‡¶∞‡¶æ‡ßü', '‡¶´‡ßá‡¶∞', '‡¶´‡¶≤‡ßá', '‡¶´‡¶ø‡¶∞‡ßá', '‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞', '‡¶¨‡¶≤‡¶§‡ßá', \n",
    "             '‡¶¨‡¶≤‡¶≤‡ßá‡¶®', '‡¶¨‡¶≤‡ßá‡¶õ‡ßá‡¶®', '‡¶¨‡¶≤‡¶≤', '‡¶¨‡¶≤‡¶æ', '‡¶¨‡¶≤‡ßá‡¶®', '‡¶¨‡¶≤‡ßá', '‡¶¨‡¶π‡ßÅ', '‡¶¨‡¶∏‡ßá', '‡¶¨‡¶æ‡¶∞', '‡¶¨‡¶æ', '‡¶¨‡¶ø‡¶®‡¶æ', '‡¶¨‡¶∞‡¶Ç', '‡¶¨‡¶¶‡¶≤‡ßá', '‡¶¨‡¶æ‡¶¶‡ßá', \n",
    "             '‡¶¨‡¶æ‡¶∞', '‡¶¨‡¶ø‡¶∂‡ßá‡¶∑', '‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶®\t‡¶¨‡¶ø‡¶∑‡ßü‡¶ü‡¶ø', '‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞', '‡¶¨‡ßç‡¶Ø‡¶æ‡¶™‡¶æ‡¶∞‡ßá', '‡¶≠‡¶æ‡¶¨‡ßá', '‡¶≠‡¶æ‡¶¨‡ßá‡¶á', '‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá', '‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá‡¶á', '‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá‡¶ì', '‡¶Æ‡¶ß‡ßç‡¶Ø‡¶≠‡¶æ‡¶ó‡ßá', \n",
    "             '‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá', '‡¶Æ‡¶æ‡¶§‡ßç‡¶∞', '‡¶Æ‡¶§‡ßã', '‡¶Æ‡¶§‡ßã‡¶á', '‡¶Æ‡ßã‡¶ü‡ßá‡¶á', '‡¶Ø‡¶ñ‡¶®', '‡¶Ø‡¶¶‡¶ø', '‡¶Ø‡¶¶‡¶ø‡¶ì', '‡¶Ø‡¶æ‡¶¨‡ßá', '‡¶Ø‡¶æ‡ßü', '‡¶Ø‡¶æ‡¶ï‡ßá', '‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ', '‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ‡¶∞', \n",
    "             '‡¶Ø‡¶§', '‡¶Ø‡¶§‡¶ü‡¶æ', '‡¶Ø‡¶æ', '‡¶Ø‡¶æ‡¶∞', '‡¶Ø‡¶æ‡¶∞‡¶æ', '‡¶Ø‡¶æ‡¶Å‡¶∞', '‡¶Ø‡¶æ‡¶Å‡¶∞‡¶æ', '‡¶Ø‡¶æ‡¶¶‡ßá‡¶∞', '‡¶Ø‡¶æ‡¶®', '‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡ßá', '‡¶Ø‡ßá‡¶§‡ßá', '‡¶Ø‡¶æ‡¶§‡ßá', '‡¶Ø‡ßá‡¶®', '‡¶Ø‡ßá‡¶Æ‡¶®', \n",
    "             '‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá', '‡¶Ø‡¶ø‡¶®‡¶ø', '‡¶Ø‡ßá', '‡¶∞‡ßá‡¶ñ‡ßá', '‡¶∞‡¶æ‡¶ñ‡¶æ', '‡¶∞‡ßü‡ßá‡¶õ‡ßá', '‡¶∞‡¶ï‡¶Æ', '‡¶∂‡ßÅ‡¶ß‡ßÅ', '‡¶∏‡¶ô‡ßç‡¶ó‡ßá', '‡¶∏‡¶ô‡ßç‡¶ó‡ßá‡¶ì', '‡¶∏‡¶Æ‡¶∏‡ßç‡¶§', '‡¶∏‡¶¨', '‡¶∏‡¶¨‡¶æ‡¶∞', '‡¶∏‡¶π', \n",
    "             '‡¶∏‡ßÅ‡¶§‡¶∞‡¶æ‡¶Ç', '‡¶∏‡¶π‡¶ø‡¶§', '‡¶∏‡ßá‡¶á', '‡¶∏‡ßá‡¶ü‡¶æ', '‡¶∏‡ßá‡¶ü‡¶ø', '‡¶∏‡ßá‡¶ü‡¶æ‡¶á', '‡¶∏‡ßá‡¶ü‡¶æ‡¶ì', '‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶§‡¶ø', '‡¶∏‡ßá‡¶ñ‡¶æ‡¶®', '‡¶∏‡ßá‡¶ñ‡¶æ‡¶®‡ßá', '‡¶∏‡ßá', '‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü', '‡¶∏‡ßç‡¶¨‡ßü‡¶Ç', \n",
    "             '‡¶π‡¶á‡¶§‡ßá', '‡¶π‡¶á‡¶¨‡ßá', '‡¶π‡ßà‡¶≤‡ßá', '‡¶π‡¶á‡ßü‡¶æ', '‡¶π‡¶ö‡ßç‡¶õ‡ßá', '‡¶π‡¶§', '‡¶π‡¶§‡ßá', '‡¶π‡¶§‡ßá‡¶á', '‡¶π‡¶¨‡ßá', '‡¶π‡¶¨‡ßá‡¶®', '‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤', '‡¶π‡ßü‡ßá‡¶õ‡ßá', '‡¶π‡ßü‡ßá‡¶õ‡ßá‡¶®', '‡¶π‡ßü‡ßá', \n",
    "             '‡¶π‡ßü‡¶®‡¶ø', '‡¶π‡ßü', '‡¶π‡ßü‡ßá‡¶á', '‡¶π‡ßü‡¶§‡ßã', '‡¶π‡¶≤', '‡¶π‡¶≤‡ßá', '‡¶π‡¶≤‡ßá‡¶á', '‡¶π‡¶≤‡ßá‡¶ì', '‡¶π‡¶≤‡ßã', '‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá', '‡¶π‡¶ì‡ßü‡¶æ', '‡¶π‡¶ì‡ßü‡¶æ‡¶∞', '‡¶π‡¶ì‡ßü‡¶æ‡ßü', '‡¶π‡¶®', \n",
    "             '‡¶π‡ßã‡¶ï', '‡¶ú‡¶®', '‡¶ú‡¶®‡¶ï‡ßá', '‡¶ú‡¶®‡ßá‡¶∞', '‡¶ú‡¶æ‡¶®‡¶§‡ßá', '‡¶ú‡¶æ‡¶®‡¶æ‡ßü', '‡¶ú‡¶æ‡¶®‡¶ø‡ßü‡ßá', '‡¶ú‡¶æ‡¶®‡¶æ‡¶®‡ßã', '‡¶ú‡¶æ‡¶®‡¶ø‡ßü‡ßá‡¶õ‡ßá', '‡¶ú‡¶®‡ßç‡¶Ø', '‡¶ú‡¶®‡ßç‡¶Ø‡¶ì‡¶ú‡ßá', '‡¶ú‡ßá', \n",
    "             '‡¶¨‡ßá‡¶∂', '‡¶¶‡ßá‡¶®', '‡¶§‡ßÅ‡¶≤‡ßá', '‡¶õ‡¶ø‡¶≤‡ßá‡¶®', '‡¶ö‡¶æ‡¶®', '‡¶ö‡¶æ‡ßü', '‡¶ö‡ßá‡ßü‡ßá', '‡¶Æ‡ßã‡¶ü', '‡¶Ø‡¶•‡ßá‡¶∑‡ßç‡¶ü', '‡¶ü‡¶ø']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_texts(sentences):\n",
    "    # tags\n",
    "    sentences = [remove_tagging(sentence) for sentence in sentences]\n",
    "    \n",
    "    # lower case\n",
    "    sentences = [sentence.lower() for sentence in sentences]\n",
    "    \n",
    "    # remove punctuations and urls \n",
    "    sentences = [remove_punc_and_urls(sentence) for sentence in sentences]\n",
    "    \n",
    "    # substitute numbers\n",
    "    sentences = [re.sub('\\\\b[0-9]+\\\\b', substitute_number, sentence) for sentence in sentences]\n",
    "    \n",
    "    # remove stopwords\n",
    "    sentences = [[word for word in sentence.split() if word not in stopwords] for sentence in sentences]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cleaning\n",
    "\n",
    "train_sentences = clean_texts(train_sentences)\n",
    "train_texts = [' '.join(l) for l in train_sentences]\n",
    "bengali_train_df['sentence'] = train_texts\n",
    "\n",
    "test_sentences = clean_texts(test_sentences)\n",
    "test_texts = [' '.join(l) for l in test_sentences]\n",
    "bengali_test_df['sentence'] = test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶∏‡¶Æ‡¶ï‡¶æ‡¶Æ‡ßÄ ‡¶π‡ßÅ‡¶ú‡ßÅ‡¶∞</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶õ‡¶æ‡¶è‡¶≤‡ßÄ‡¶ó ‡¶∏‡¶æ‡¶≤‡¶æ ‡¶¶‡ßá‡¶∞ ‡¶®‡¶ø‡¶∏‡¶ø‡¶¶‡ßç‡¶¶ ‡¶π‡¶ï</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶ï‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡¶¶‡¶ø ‡¶õ‡¶æ‡¶∞‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ú‡¶¨‡ßá ‡¶ú‡ßÅ‡¶§‡¶æ ‡¶ï‡ßá‡¶Æ‡¶®‡ßá ‡¶ñ‡¶æ‡ßü</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶ï‡¶æ‡¶â‡ßü‡¶æ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶¨‡ßú ‡¶Æ‡¶æ‡¶ó‡ßÄ‡¶ñ‡ßã‡¶∞ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶™‡¶ø‡¶ï ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ù‡¶æ ‡¶≤‡ßÅ...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶Ö‡¶™‡ßÅ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶•‡¶æ ‡¶õ‡ßã‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá‡¶®‡¶æ</td>\n",
       "      <td>0</td>\n",
       "      <td>Meme, TikTok and others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate  \\\n",
       "0                                       ‡¶∏‡¶Æ‡¶ï‡¶æ‡¶Æ‡ßÄ ‡¶π‡ßÅ‡¶ú‡ßÅ‡¶∞     0   \n",
       "1                         ‡¶õ‡¶æ‡¶è‡¶≤‡ßÄ‡¶ó ‡¶∏‡¶æ‡¶≤‡¶æ ‡¶¶‡ßá‡¶∞ ‡¶®‡¶ø‡¶∏‡¶ø‡¶¶‡ßç‡¶¶ ‡¶π‡¶ï     1   \n",
       "2               ‡¶ï‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡¶¶‡¶ø ‡¶õ‡¶æ‡¶∞‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ú‡¶¨‡ßá ‡¶ú‡ßÅ‡¶§‡¶æ ‡¶ï‡ßá‡¶Æ‡¶®‡ßá ‡¶ñ‡¶æ‡ßü     0   \n",
       "3  ‡¶ï‡¶æ‡¶â‡ßü‡¶æ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶¨‡ßú ‡¶Æ‡¶æ‡¶ó‡ßÄ‡¶ñ‡ßã‡¶∞ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶™‡¶ø‡¶ï ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ù‡¶æ ‡¶≤‡ßÅ...     1   \n",
       "4                            ‡¶Ö‡¶™‡ßÅ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶•‡¶æ ‡¶õ‡ßã‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá‡¶®‡¶æ     0   \n",
       "\n",
       "                  category  \n",
       "0                 religion  \n",
       "1                 politics  \n",
       "2                 politics  \n",
       "3                 politics  \n",
       "4  Meme, TikTok and others  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ‡¶ï‡ßá ‡¶∞‡¶ø‡¶Æ‡¶æ‡¶®‡¶°‡ßá</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶§‡ßÅ‡¶∞ ‡¶∞‡¶ø‡¶™‡¶æ‡¶§‡¶ï‡ßá ‡¶Æ‡¶® ‡¶ö‡¶æ‡¶á‡¶õ‡¶ø‡¶≤ ‡¶õ‡ßá‡¶°‡¶º‡ßá ‡¶ó‡ßá‡¶≤‡¶ø ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡¶ø‡¶§‡ßç‡¶Ø‡ßá ‡¶Ö...</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶π‡ßÅ‡¶Æ‡¶æ‡ßü‡ßÅ‡¶® ‡¶Ü‡¶ú‡¶æ‡¶¶ ‡¶è‡¶§‡ßã ‡¶¨‡ßú ‡¶ï‡ßç‡¶∞‡¶æ‡¶ï ‡¶Æ‡¶æ‡¶§‡¶æ‡¶≤</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶¨‡¶æ‡¶Ç‡¶æ‡¶≤ ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶∏‡¶æ‡¶π‡¶∏‡¶ø ‡¶á‡¶â‡¶ü‡ßÅ‡¶¨‡¶æ‡¶∞üëçüëçüëç</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ß‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ ‡¶ö‡ßã‡¶∞ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶´‡¶æ‡¶ü‡¶æ ‡¶ï‡ßá‡¶∑‡ßç‡¶ü ‡¶ï‡ßã‡¶á ...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate  category\n",
       "0                                    ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ‡¶ï‡ßá ‡¶∞‡¶ø‡¶Æ‡¶æ‡¶®‡¶°‡ßá     0     crime\n",
       "1  ‡¶§‡ßÅ‡¶∞ ‡¶∞‡¶ø‡¶™‡¶æ‡¶§‡¶ï‡ßá ‡¶Æ‡¶® ‡¶ö‡¶æ‡¶á‡¶õ‡¶ø‡¶≤ ‡¶õ‡ßá‡¶°‡¶º‡ßá ‡¶ó‡ßá‡¶≤‡¶ø ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡¶ø‡¶§‡ßç‡¶Ø‡ßá ‡¶Ö...     0     crime\n",
       "2                    ‡¶π‡ßÅ‡¶Æ‡¶æ‡ßü‡ßÅ‡¶® ‡¶Ü‡¶ú‡¶æ‡¶¶ ‡¶è‡¶§‡ßã ‡¶¨‡ßú ‡¶ï‡ßç‡¶∞‡¶æ‡¶ï ‡¶Æ‡¶æ‡¶§‡¶æ‡¶≤     0  religion\n",
       "3                ‡¶¨‡¶æ‡¶Ç‡¶æ‡¶≤ ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶∏‡¶æ‡¶π‡¶∏‡¶ø ‡¶á‡¶â‡¶ü‡ßÅ‡¶¨‡¶æ‡¶∞üëçüëçüëç     0  politics\n",
       "4  ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ß‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ ‡¶ö‡ßã‡¶∞ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶´‡¶æ‡¶ü‡¶æ ‡¶ï‡ßá‡¶∑‡ßç‡¶ü ‡¶ï‡ßã‡¶á ...     1  politics"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('train:')\n",
    "display(bengali_train_df.head())\n",
    "print('test:')\n",
    "display(bengali_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab and Word <-> int transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 15190\n"
     ]
    }
   ],
   "source": [
    "train_sentences = [sentence.split() for sentence in bengali_train_df['sentence']]\n",
    "test_sentences = [sentence.split() for sentence in bengali_test_df['sentence']]\n",
    "\n",
    "flattened_words = [word for sentence in train_sentences for word in sentence]\n",
    "V = sorted(list(set(flattened_words)))\n",
    "vocab_size = len(V)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "\n",
    "word_to_int = {}\n",
    "int_to_word = {}\n",
    "for i, word in enumerate(V):\n",
    "    word_to_int[word] = i\n",
    "    int_to_word[i] = word\n",
    "\n",
    "# save dicts for transformation word <-> int\n",
    "with open('save/bengali_word_to_int_dict.json', 'w') as f:\n",
    "    json.dump(word_to_int, f)\n",
    "with open('save/bengali_int_to_word_dict.json', 'w') as f:\n",
    "    json.dump(int_to_word, f)    \n",
    "\n",
    "# save word-counter for sampling\n",
    "word_counter = Counter(flattened_words)\n",
    "with open('save/bengali_word_counter.json', 'w') as f:\n",
    "    json.dump(word_counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [[word_to_int[word] for word in sentence] for sentence in train_sentences]\n",
    "test_sentences = [[word_to_int[word] for word in sentence if word in word_to_int] for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude empty sentences\n",
    "\n",
    "train_texts = [' '.join([str(v) for v in l]) for l in train_sentences]\n",
    "bengali_train_df['sentence'] = train_texts\n",
    "bengali_train_df = bengali_train_df[bengali_train_df['sentence'].str.len() != 0].reset_index(drop=True)\n",
    "\n",
    "test_texts = [' '.join([str(v) for v in l]) for l in test_sentences]\n",
    "bengali_test_df['sentence'] = test_texts\n",
    "bengali_test_df = bengali_test_df[bengali_test_df['sentence'].str.len() != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13549 14750</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4677 13865 6879 7552 14359</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2563 3604 4734 10256 5319 3038 3435</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2556 2633 10699 11348 10994 8322 6775 10290 12...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>388 10938 2116 4863 2323</td>\n",
       "      <td>0</td>\n",
       "      <td>Meme, TikTok and others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate  \\\n",
       "0                                        13549 14750     0   \n",
       "1                         4677 13865 6879 7552 14359     1   \n",
       "2                2563 3604 4734 10256 5319 3038 3435     0   \n",
       "3  2556 2633 10699 11348 10994 8322 6775 10290 12...     1   \n",
       "4                           388 10938 2116 4863 2323     0   \n",
       "\n",
       "                  category  \n",
       "0                 religion  \n",
       "1                 politics  \n",
       "2                 politics  \n",
       "3                 politics  \n",
       "4  Meme, TikTok and others  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11279</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6010 11176 4155 4831 3905 13755 469 2339 6616 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14766 798 1815 10699 11394</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6910 13519 13912</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2633 6992 11400 4605 2633 1669 8999 3079 12437...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate  category\n",
       "0                                              11279     0     crime\n",
       "1  6010 11176 4155 4831 3905 13755 469 2339 6616 ...     0     crime\n",
       "2                         14766 798 1815 10699 11394     0  religion\n",
       "3                                   6910 13519 13912     0  politics\n",
       "4  2633 6992 11400 4605 2633 1669 8999 3079 12437...     1  politics"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bengali_train_df.head())\n",
    "display(bengali_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bengali_train_df.to_csv('save/bengali_hatespeech_sample_train_preprocessed.csv', index=False)\n",
    "bengali_test_df.to_csv('save/bengali_hatespeech_sample_test_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
