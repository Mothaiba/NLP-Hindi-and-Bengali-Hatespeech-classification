{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make embeddings for Bengali language\n",
    "This notebook handles the embedding process.\n",
    "\n",
    "### Input:\n",
    "    - Pre-processed training dataframe.\n",
    "\n",
    "### Output:\n",
    "    - The trained weights of the embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f35c4ef9f90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(62)\n",
    "torch.manual_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 55189\n",
      "total word occurences: 303627\n"
     ]
    }
   ],
   "source": [
    "ben_train_df = pd.read_csv('save/bengali_hatespeech_embed_train_preprocessed.csv')\n",
    "# remove empty texts\n",
    "ben_train_df = ben_train_df[ben_train_df.sentence.str.len() > 0]\n",
    "\n",
    "# load mapping {word -> id} and {id -> word}\n",
    "with open('save/word_to_int_dict.json') as f:\n",
    "    word_to_int = json.load(f)\n",
    "with open('save/int_to_word_dict.json') as f:\n",
    "    int_to_word = json.load(f)\n",
    "    int_to_word = {int(k) : v for k, v in int_to_word.items()}\n",
    "with open('save/word_counter.json') as f:\n",
    "    word_counter = json.load(f)\n",
    "\n",
    "# get vocab_size\n",
    "vocab_size = len(word_to_int)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "\n",
    "# get total occurences\n",
    "total_words = sum(word_counter.values())\n",
    "print(f'total word occurences: {total_words}')\n",
    "\n",
    "# extract sentences and labels\n",
    "train_sentences = [[word_to_int[w] for w in text.split()] for text in ben_train_df['sentence']]\n",
    "train_labels = ben_train_df['hate'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'save/word2vec_neg.pt'\n",
    "\n",
    "window_size = 5\n",
    "embedding_size = 300\n",
    "neg_sample_factor = 10\n",
    "noise_dist_alpha = 3/4\n",
    "learning_rate = 0.01\n",
    "lr_decay = lambda epoch: max(0.05, 0.9**epoch)\n",
    "batch_size = 256\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling probability of pair (center, context)\n",
    "def sampling_prob(word):\n",
    "    z = word_counter[word] / total_words\n",
    "    p_keep = ((z/0.000001)**0.5 + 1) * (0.000001/z)\n",
    "    return p_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise distribution\n",
    "noisy_words = [iw for iw in int_to_word]\n",
    "noisy_dist = np.array([(word_counter[int_to_word[iw]]/total_words)**noise_dist_alpha for iw in noisy_words])\n",
    "noisy_dist = noisy_dist / noisy_dist.sum()\n",
    "\n",
    "# noisy word generator\n",
    "def get_noise_word(batch_size, neg_factor):\n",
    "    noise_list = np.random.choice(noisy_words, batch_size*neg_factor, p=noisy_dist)\n",
    "    noise_list = noise_list.reshape((batch_size, neg_factor))\n",
    "    return torch.from_numpy(noise_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_context(sentence: list(str())):\n",
    "    for i, word in enumerate(sentence):\n",
    "        for j, context_word in enumerate(sentence[i-window_size:i+window_size+1]):\n",
    "            if j != i and random.random() < sampling_prob(int_to_word[context_word]):\n",
    "                    yield (torch.tensor(word, dtype=torch.long), \n",
    "                           torch.tensor(context_word, dtype=torch.long)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train word-embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Word2Vec(\n",
       "  (center_embed): Embedding(55189, 300)\n",
       "  (context_embed): Embedding(55189, 300)\n",
       "  (log_sigmoid): LogSigmoid()\n",
       ")>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Word2Vec(Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.center_embed = nn.Embedding(vocab_size, embedding_size)        \n",
    "        self.context_embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        init_range = (2 / (vocab_size + embedding_size)) ** 0.5\n",
    "        self.center_embed.weight.data.uniform_(-init_range, init_range)\n",
    "        self.context_embed.weight.data.uniform_(-init_range, init_range)\n",
    "        \n",
    "        self.log_sigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, center_ids, context_ids, negative_samples):\n",
    "        # center_ids, context_ids: [batch_size]\n",
    "        # negatve_samples: [batch_size, neg_sample_factor]\n",
    "        \n",
    "        # center_embed, context_embed: [batch_size, embedding_size]\n",
    "        center_embed = self.center_embed(center_ids)\n",
    "        context_embed = self.context_embed(context_ids)\n",
    "        \n",
    "        # pos_dot: [batch_size]\n",
    "        pos_dot = (center_embed * context_embed).sum(axis=1)\n",
    "        \n",
    "        # pos_loss: [batch_size]\n",
    "        pos_loss = self.log_sigmoid(pos_dot)\n",
    "        \n",
    "        # negative_embed: [batch_size, neg_sample_factor, embedding_size]\n",
    "        negative_embed = self.context_embed(negative_samples)\n",
    "        \n",
    "        # negs_dot: [batch_size, neg_sample_factor]\n",
    "        negs_dot = torch.bmm(negative_embed, center_embed.unsqueeze(2)).squeeze(2) * (-1)\n",
    "        \n",
    "        # neg_dot: [batch_size]\n",
    "        neg_dot = negs_dot.sum(axis=1)\n",
    "        \n",
    "        # neg_loss: [batch_size]\n",
    "        neg_loss = self.log_sigmoid(neg_dot)\n",
    "        \n",
    "        loss = -(pos_loss + neg_loss).sum()\n",
    "        return loss, -pos_loss.sum(), -neg_loss.sum()\n",
    "    \n",
    "    def to_embed(self, center_id):\n",
    "        return self.center_embed(center_id)\n",
    "    \n",
    "word2vec = Word2Vec()\n",
    "torch.save(word2vec.state_dict(), model_save_path)\n",
    "\n",
    "display(word2vec.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Learning-rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(word2vec.parameters(), lr=learning_rate)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2VDataset(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.data = []\n",
    "        for sentence in sentences:\n",
    "            for data_point in get_target_context(sentence):\n",
    "                self.data.append(data_point)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:31<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: training loss: 1.4110 (pos: 1.0727, neg: 0.0338) over 423521 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:28<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2: training loss: 1.3803 (pos: 0.9942, neg: 0.0386) over 424083 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:29<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3: training loss: 1.2126 (pos: 0.8699, neg: 0.0343) over 424038 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:29<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4: training loss: 1.0393 (pos: 0.7624, neg: 0.0277) over 424571 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:29<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5: training loss: 0.9001 (pos: 0.6663, neg: 0.0234) over 424019 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:29<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6: training loss: 0.7711 (pos: 0.5760, neg: 0.0195) over 423453 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:29<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7: training loss: 0.6679 (pos: 0.5023, neg: 0.0166) over 423691 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1653/1653 [02:29<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8: training loss: 0.5844 (pos: 0.4399, neg: 0.0144) over 423090 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:29<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9: training loss: 0.5071 (pos: 0.3832, neg: 0.0124) over 424610 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:30<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: training loss: 0.4510 (pos: 0.3418, neg: 0.0109) over 423982 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: training loss: 0.3958 (pos: 0.2992, neg: 0.0097) over 424160 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1660/1660 [02:31<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: training loss: 0.3537 (pos: 0.2668, neg: 0.0087) over 424767 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: training loss: 0.3115 (pos: 0.2365, neg: 0.0075) over 423873 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: training loss: 0.2826 (pos: 0.2154, neg: 0.0067) over 423825 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:34<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: training loss: 0.2561 (pos: 0.1930, neg: 0.0063) over 423580 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: training loss: 0.2315 (pos: 0.1751, neg: 0.0056) over 424074 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: training loss: 0.2115 (pos: 0.1600, neg: 0.0052) over 424032 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:31<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: training loss: 0.1953 (pos: 0.1462, neg: 0.0049) over 424482 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:32<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: training loss: 0.1780 (pos: 0.1343, neg: 0.0044) over 423645 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:27<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: training loss: 0.1664 (pos: 0.1234, neg: 0.0043) over 424431 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:35<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: training loss: 0.1573 (pos: 0.1165, neg: 0.0041) over 424185 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:29<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: training loss: 0.1461 (pos: 0.1084, neg: 0.0038) over 424027 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:32<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: training loss: 0.1353 (pos: 0.0996, neg: 0.0036) over 424224 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:28<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: training loss: 0.1294 (pos: 0.0943, neg: 0.0035) over 423735 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:28<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: training loss: 0.1245 (pos: 0.0912, neg: 0.0033) over 424245 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:28<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss: 0.1184 (pos: 0.0872, neg: 0.0031) over 423512 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:30<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: training loss: 0.1132 (pos: 0.0819, neg: 0.0031) over 424207 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:29<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: training loss: 0.1125 (pos: 0.0819, neg: 0.0031) over 423903 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1660/1660 [02:35<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: training loss: 0.1064 (pos: 0.0765, neg: 0.0030) over 424720 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:32<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: training loss: 0.1042 (pos: 0.0754, neg: 0.0029) over 424109 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: training loss: 0.1020 (pos: 0.0722, neg: 0.0030) over 424095 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:30<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: training loss: 0.0990 (pos: 0.0690, neg: 0.0030) over 424041 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:31<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: training loss: 0.0947 (pos: 0.0666, neg: 0.0028) over 424373 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:32<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: training loss: 0.0947 (pos: 0.0662, neg: 0.0028) over 423572 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:34<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: training loss: 0.0926 (pos: 0.0651, neg: 0.0028) over 423692 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:37<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: training loss: 0.0879 (pos: 0.0623, neg: 0.0026) over 424129 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [02:36<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: training loss: 0.0855 (pos: 0.0595, neg: 0.0026) over 423276 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:36<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: training loss: 0.0845 (pos: 0.0590, neg: 0.0025) over 423686 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:34<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: training loss: 0.0834 (pos: 0.0573, neg: 0.0026) over 423433 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:38<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: training loss: 0.0801 (pos: 0.0552, neg: 0.0025) over 424295 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: training loss: 0.0793 (pos: 0.0549, neg: 0.0024) over 424066 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:40<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: training loss: 0.0768 (pos: 0.0523, neg: 0.0024) over 424283 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:36<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: training loss: 0.0768 (pos: 0.0513, neg: 0.0026) over 424205 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:36<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: training loss: 0.0739 (pos: 0.0496, neg: 0.0024) over 423547 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:32<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: training loss: 0.0736 (pos: 0.0492, neg: 0.0024) over 424071 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:31<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: training loss: 0.0732 (pos: 0.0488, neg: 0.0024) over 424454 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:34<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: training loss: 0.0722 (pos: 0.0467, neg: 0.0026) over 423743 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:34<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: training loss: 0.0713 (pos: 0.0462, neg: 0.0025) over 424044 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [02:34<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: training loss: 0.0680 (pos: 0.0451, neg: 0.0023) over 423230 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: training loss: 0.0683 (pos: 0.0443, neg: 0.0024) over 423795 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss: 0.0659 (pos: 0.0430, neg: 0.0023) over 424104 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:35<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: training loss: 0.0656 (pos: 0.0426, neg: 0.0023) over 424401 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: training loss: 0.0651 (pos: 0.0416, neg: 0.0024) over 423653 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: training loss: 0.0649 (pos: 0.0412, neg: 0.0024) over 423876 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: training loss: 0.0636 (pos: 0.0408, neg: 0.0023) over 423609 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:35<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: training loss: 0.0633 (pos: 0.0398, neg: 0.0024) over 424686 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: training loss: 0.0621 (pos: 0.0393, neg: 0.0023) over 423873 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: training loss: 0.0590 (pos: 0.0385, neg: 0.0020) over 423920 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:35<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: training loss: 0.0606 (pos: 0.0371, neg: 0.0023) over 424577 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:35<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: training loss: 0.0576 (pos: 0.0361, neg: 0.0021) over 424027 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:32<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: training loss: 0.0589 (pos: 0.0362, neg: 0.0023) over 424211 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:32<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: training loss: 0.0578 (pos: 0.0356, neg: 0.0022) over 423936 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: training loss: 0.0561 (pos: 0.0345, neg: 0.0022) over 424028 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [02:31<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: training loss: 0.0571 (pos: 0.0352, neg: 0.0022) over 423243 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:32<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: training loss: 0.0549 (pos: 0.0337, neg: 0.0021) over 423879 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:32<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: training loss: 0.0548 (pos: 0.0325, neg: 0.0022) over 424337 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: training loss: 0.0539 (pos: 0.0320, neg: 0.0022) over 423598 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1652/1652 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: training loss: 0.0532 (pos: 0.0322, neg: 0.0021) over 422750 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:31<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: training loss: 0.0533 (pos: 0.0319, neg: 0.0021) over 424341 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: training loss: 0.0512 (pos: 0.0304, neg: 0.0021) over 424267 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: training loss: 0.0526 (pos: 0.0307, neg: 0.0022) over 423928 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:32<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: training loss: 0.0523 (pos: 0.0302, neg: 0.0022) over 424491 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: training loss: 0.0510 (pos: 0.0295, neg: 0.0022) over 424019 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: training loss: 0.0501 (pos: 0.0288, neg: 0.0021) over 423890 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: training loss: 0.0503 (pos: 0.0292, neg: 0.0021) over 424456 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: training loss: 0.0500 (pos: 0.0285, neg: 0.0021) over 423347 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: training loss: 0.0496 (pos: 0.0281, neg: 0.0021) over 424039 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: training loss: 0.0493 (pos: 0.0283, neg: 0.0021) over 423699 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: training loss: 0.0487 (pos: 0.0276, neg: 0.0021) over 423738 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: training loss: 0.0479 (pos: 0.0269, neg: 0.0021) over 424143 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:32<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: training loss: 0.0472 (pos: 0.0267, neg: 0.0020) over 424451 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1660/1660 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: training loss: 0.0482 (pos: 0.0271, neg: 0.0021) over 424882 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: training loss: 0.0471 (pos: 0.0264, neg: 0.0021) over 423804 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1659/1659 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: training loss: 0.0457 (pos: 0.0251, neg: 0.0021) over 424479 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: training loss: 0.0477 (pos: 0.0259, neg: 0.0022) over 424321 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: training loss: 0.0444 (pos: 0.0249, neg: 0.0020) over 423488 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: training loss: 0.0459 (pos: 0.0253, neg: 0.0021) over 423805 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:32<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: training loss: 0.0465 (pos: 0.0252, neg: 0.0021) over 424023 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [02:31<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: training loss: 0.0461 (pos: 0.0245, neg: 0.0022) over 424169 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [02:33<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: training loss: 0.0445 (pos: 0.0244, neg: 0.0020) over 423632 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [02:40<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: training loss: 0.0445 (pos: 0.0242, neg: 0.0020) over 423789 training points.\n",
      "Early stopping: training loss does not decrease after 5 epochs\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# load initial weights\n",
    "word2vec.load_state_dict(torch.load(model_save_path, map_location=torch.device(device)))\n",
    "word2vec = word2vec.to(device)\n",
    "\n",
    "early_stop = 5\n",
    "history_losses = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_dataset = W2VDataset(train_sentences)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    losses, pos_losses, neg_losses = 0., 0., 0.\n",
    "    cnt = 0\n",
    "    \n",
    "    word2vec.train()\n",
    "    for center_words, context_words in tqdm(train_loader):\n",
    "        negative_samples = get_noise_word(len(center_words), neg_sample_factor)\n",
    "        optimizer.zero_grad()\n",
    "        loss, pos_loss, neg_loss = word2vec(center_words.to(device), context_words.to(device), negative_samples.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss\n",
    "        cnt += len(center_words)\n",
    "        pos_losses += pos_loss\n",
    "        neg_losses += neg_loss\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_loss = losses / cnt\n",
    "    print(f'Epoch {epoch:2}: training loss: {epoch_loss:.4f} (pos: {pos_losses/cnt:.4f}, neg: {neg_losses/(cnt*neg_sample_factor):.4f}) over {cnt} training points.')\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        # save embedding\n",
    "        embedding_weights = word2vec.center_embed.state_dict()\n",
    "        torch.save(embedding_weights, f'save/embedding_checkpoints/{epoch}_epoch_{embedding_size}_dim_{window_size}_wsize_{neg_sample_factor}_negfac.pt')\n",
    "    \n",
    "    history_losses.append(epoch_loss)\n",
    "    if len(history_losses) > early_stop and min(history_losses[-early_stop:]) >= min(history_losses[:-early_stop]):\n",
    "        print(f'Early stopping: training loss does not decrease after {early_stop} epochs')\n",
    "        break\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedding weights\n",
    "embedding_weights = word2vec.center_embed.state_dict()\n",
    "torch.save(embedding_weights, f'save/big_embedding_weights_{window_size}_wsize_{neg_sample_factor}_negfac.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
