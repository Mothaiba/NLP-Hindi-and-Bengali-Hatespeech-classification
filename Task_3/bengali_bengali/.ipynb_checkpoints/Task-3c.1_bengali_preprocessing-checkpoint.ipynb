{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(62)\n",
    "torch.manual_seed(2021)\n",
    "torch.cuda.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Bengali datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample Bengali datasets\n",
    "bengali_train_df = pd.read_csv('../../Task_2/hindi_bengali/save/bengali_hatespeech_sample_train.csv')\n",
    "bengali_test_df = pd.read_csv('../../Task_2/hindi_bengali/save/bengali_hatespeech_sample_test.csv')\n",
    "bengali_other_df = pd.read_csv('../../Task_2/hindi_bengali/save/bengali_hatespeech_other.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = bengali_train_df['sentence']\n",
    "test_sentences = bengali_test_df['sentence']\n",
    "other_sentences = bengali_other_df['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove user taggings\n",
    "user_tag_pattern = re.compile(r'\\@\\w*')\n",
    "def remove_tagging(sentence):\n",
    "    return re.sub(user_tag_pattern, ' ', sentence)\n",
    "\n",
    "# remove punctuations and urls\n",
    "http_re = re.compile('http://[^ ]*')\n",
    "https_re = re.compile('https://[^ ]*')\n",
    "punctuation = string.punctuation[:2] + string.punctuation[3:]\n",
    "translator = str.maketrans(punctuation, ' '*len(punctuation))\n",
    "def remove_punc_and_urls(s):\n",
    "    s = re.sub(http_re, ' ', s)\n",
    "    s = re.sub(https_re, ' ', s)\n",
    "    s = s.translate(translator)\n",
    "    return s\n",
    "\n",
    "# substitute numbers\n",
    "#   when there is a number in the string:\n",
    "#   if that number is 0 or 1 or 2, then there is no change.\n",
    "#   else, that number is substituted by a word describing how many digits it has.\n",
    "def substitute_number(x):\n",
    "    x = x.group(0)\n",
    "    if x in {'0', '1', '2'}:\n",
    "        return x\n",
    "    return '{}_digits_number'.format(len(x))\n",
    "\n",
    "# stopwords BENGALI (source: https://www.ranks.nl/stopwords/bengali)\n",
    "stopwords = ['‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø', '‡¶Ö‡¶®‡ßá‡¶ï', '‡¶Ö‡¶®‡ßá‡¶ï‡ßá', '‡¶Ö‡¶®‡ßá‡¶ï‡ßá‡¶á', '‡¶Ö‡¶®‡ßç‡¶§‡¶§', '‡¶Ö‡¶•‡¶¨‡¶æ', '‡¶Ö‡¶•‡¶ö', '‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡¶§', '‡¶Ö‡¶®‡ßç‡¶Ø', '‡¶Ü‡¶ú', '‡¶Ü‡¶õ‡ßá', '‡¶Ü‡¶™‡¶®‡¶æ‡¶∞', \n",
    "             '‡¶Ü‡¶™‡¶®‡¶ø', '‡¶Ü‡¶¨‡¶æ‡¶∞', '‡¶Ü‡¶Æ‡¶∞‡¶æ', '‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá', '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞', '‡¶Ü‡¶Æ‡¶æ‡¶∞', '‡¶Ü‡¶Æ‡¶ø', '‡¶Ü‡¶∞‡¶ì', '‡¶Ü‡¶∞', '‡¶Ü‡¶ó‡ßá', '‡¶Ü‡¶ó‡ßá‡¶á', '‡¶Ü‡¶á', \n",
    "             '‡¶Ö‡¶§‡¶è‡¶¨', '‡¶Ü‡¶ó‡¶æ‡¶Æ‡ßÄ', '‡¶Ö‡¶¨‡¶ß‡¶ø', '‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ', '‡¶Ü‡¶¶‡ßç‡¶Ø‡¶≠‡¶æ‡¶ó‡ßá', '‡¶è‡¶á', '‡¶è‡¶ï‡¶á', '‡¶è‡¶ï‡ßá', '‡¶è‡¶ï‡¶ü‡¶ø', '‡¶è‡¶ñ‡¶®', '‡¶è‡¶ñ‡¶®‡¶ì', '‡¶è‡¶ñ‡¶æ‡¶®‡ßá', \n",
    "             '‡¶è‡¶ñ‡¶æ‡¶®‡ßá‡¶á', '‡¶è‡¶ü‡¶ø', '‡¶è‡¶ü‡¶æ', '‡¶è‡¶ü‡¶æ‡¶á', '‡¶è‡¶§‡¶ü‡¶æ‡¶á', '‡¶è‡¶¨‡¶Ç', '‡¶è‡¶ï‡¶¨‡¶æ‡¶∞', '‡¶è‡¶¨‡¶æ‡¶∞', '‡¶è‡¶¶‡ßá‡¶∞', '‡¶è‡¶Å‡¶¶‡ßá‡¶∞', '‡¶è‡¶Æ‡¶®', '‡¶è‡¶Æ‡¶®‡¶ï‡ßÄ', '‡¶è‡¶≤', \n",
    "             '‡¶è‡¶∞', '‡¶è‡¶∞‡¶æ', '‡¶è‡¶Å‡¶∞‡¶æ', '‡¶è‡¶∏', '‡¶è‡¶§', '‡¶è‡¶§‡ßá', '‡¶è‡¶∏‡ßá', '‡¶è‡¶ï‡ßá', '‡¶è', '‡¶ê', ' ‡¶á', '‡¶á‡¶π‡¶æ', '‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø', '‡¶â‡¶®‡¶ø', '‡¶â‡¶™‡¶∞', \n",
    "             '‡¶â‡¶™‡¶∞‡ßá', '‡¶â‡¶ö‡¶ø‡¶§', '‡¶ì', '‡¶ì‡¶á', '‡¶ì‡¶∞', '‡¶ì‡¶∞‡¶æ', '‡¶ì‡¶Å‡¶∞', '‡¶ì‡¶Å‡¶∞‡¶æ', '‡¶ì‡¶ï‡ßá', '‡¶ì‡¶¶‡ßá‡¶∞', '‡¶ì‡¶Å‡¶¶‡ßá‡¶∞', '‡¶ì‡¶ñ‡¶æ‡¶®‡ßá', '‡¶ï‡¶§', '‡¶ï‡¶¨‡ßá', \n",
    "             '‡¶ï‡¶∞‡¶§‡ßá', '‡¶ï‡ßü‡ßá‡¶ï', '‡¶ï‡ßü‡ßá‡¶ï‡¶ü‡¶ø', '‡¶ï‡¶∞‡¶¨‡ßá', '‡¶ï‡¶∞‡¶≤‡ßá‡¶®', '‡¶ï‡¶∞‡¶æ‡¶∞', '‡¶ï‡¶æ‡¶∞‡¶ì', '‡¶ï‡¶∞‡¶æ', '‡¶ï‡¶∞‡¶ø', '‡¶ï‡¶∞‡¶ø‡ßü‡ßá', '‡¶ï‡¶∞‡¶æ‡¶∞', '‡¶ï‡¶∞‡¶æ‡¶á', \n",
    "             '‡¶ï‡¶∞‡¶≤‡ßá', '‡¶ï‡¶∞‡¶≤‡ßá‡¶®', '‡¶ï‡¶∞‡¶ø‡¶§‡ßá', '‡¶ï‡¶∞‡¶ø‡ßü‡¶æ', '‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡¶≤‡ßá‡¶®', '‡¶ï‡¶∞‡¶õ‡ßá', '‡¶ï‡¶∞‡¶õ‡ßá‡¶®', '‡¶ï‡¶∞‡ßá‡¶õ‡ßá‡¶®', '‡¶ï‡¶∞‡ßá‡¶õ‡ßá', '‡¶ï‡¶∞‡ßá‡¶®', '‡¶ï‡¶∞‡¶¨‡ßá‡¶®', \n",
    "             '‡¶ï‡¶∞‡¶æ‡ßü', '‡¶ï‡¶∞‡ßá', '‡¶ï‡¶∞‡ßá‡¶á', '‡¶ï‡¶æ‡¶õ', '‡¶ï‡¶æ‡¶õ‡ßá', '‡¶ï‡¶æ‡¶ú‡ßá', '‡¶ï‡¶æ‡¶∞‡¶£', '‡¶ï‡¶ø‡¶õ‡ßÅ', '‡¶ï‡¶ø‡¶õ‡ßÅ‡¶á', '‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ', '‡¶ï‡¶ø‡¶Ç‡¶¨‡¶æ', '‡¶ï‡¶ø', '‡¶ï‡ßÄ', '‡¶ï‡ßá‡¶â', \n",
    "             '‡¶ï‡ßá‡¶â‡¶á', '‡¶ï‡¶æ‡¶â‡¶ï‡ßá', '‡¶ï‡ßá‡¶®', '‡¶ï‡ßá', '‡¶ï‡ßã‡¶®‡¶ì', '‡¶ï‡ßã‡¶®‡ßã', '‡¶ï‡ßã‡¶®', '‡¶ï‡¶ñ‡¶®‡¶ì', '‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá', '‡¶ñ‡ßÅ‡¶¨\t‡¶ó‡ßÅ‡¶≤‡¶ø', '‡¶ó‡¶ø‡ßü‡ßá', '‡¶ó‡¶ø‡ßü‡ßá‡¶õ‡ßá', \n",
    "             '‡¶ó‡ßá‡¶õ‡ßá', '‡¶ó‡ßá‡¶≤', '‡¶ó‡ßá‡¶≤‡ßá', '‡¶ó‡ßã‡¶ü‡¶æ', '‡¶ö‡¶≤‡ßá', '‡¶õ‡¶æ‡ßú‡¶æ', '‡¶õ‡¶æ‡ßú‡¶æ‡¶ì', '‡¶õ‡¶ø‡¶≤‡ßá‡¶®', '‡¶õ‡¶ø‡¶≤', '‡¶ú‡¶®‡ßç‡¶Ø', '‡¶ú‡¶æ‡¶®‡¶æ', '‡¶†‡¶ø‡¶ï', '‡¶§‡¶ø‡¶®‡¶ø', \n",
    "             '‡¶§‡¶ø‡¶®‡¶ê', '‡¶§‡¶ø‡¶®‡¶ø‡¶ì', '‡¶§‡¶ñ‡¶®', '‡¶§‡¶¨‡ßá', '‡¶§‡¶¨‡ßÅ', '‡¶§‡¶æ‡¶Å‡¶¶‡ßá‡¶∞', '‡¶§‡¶æ‡¶Å‡¶æ‡¶π‡¶æ‡¶∞‡¶æ', '‡¶§‡¶æ‡¶Å‡¶∞‡¶æ', '‡¶§‡¶æ‡¶Å‡¶∞', '‡¶§‡¶æ‡¶Å‡¶ï‡ßá', '‡¶§‡¶æ‡¶á', '‡¶§‡ßá‡¶Æ‡¶®', '‡¶§‡¶æ‡¶ï‡ßá', \n",
    "             '‡¶§‡¶æ‡¶π‡¶æ', '‡¶§‡¶æ‡¶π‡¶æ‡¶§‡ßá', '‡¶§‡¶æ‡¶π‡¶æ‡¶∞', '‡¶§‡¶æ‡¶¶‡ßá‡¶∞', '‡¶§‡¶æ‡¶∞‡¶™‡¶∞', '‡¶§‡¶æ‡¶∞‡¶æ', '‡¶§‡¶æ‡¶∞‡ßà', '‡¶§‡¶æ‡¶∞', '‡¶§‡¶æ‡¶π‡¶≤‡ßá', '‡¶§‡¶ø‡¶®‡¶ø', '‡¶§‡¶æ', '‡¶§‡¶æ‡¶ì', '‡¶§‡¶æ‡¶§‡ßá', \n",
    "             '‡¶§‡ßã', '‡¶§‡¶§', '‡¶§‡ßÅ‡¶Æ‡¶ø', '‡¶§‡ßã‡¶Æ‡¶æ‡¶∞', '‡¶§‡¶•‡¶æ', '‡¶•‡¶æ‡¶ï‡ßá', '‡¶•‡¶æ‡¶ï‡¶æ', '‡¶•‡¶æ‡¶ï‡¶æ‡ßü', '‡¶•‡ßá‡¶ï‡ßá', '‡¶•‡ßá‡¶ï‡ßá‡¶ì', '‡¶•‡¶æ‡¶ï‡¶¨‡ßá', '‡¶•‡¶æ‡¶ï‡ßá‡¶®', '‡¶•‡¶æ‡¶ï‡¶¨‡ßá‡¶®', \n",
    "             '‡¶•‡ßá‡¶ï‡ßá‡¶á', '‡¶¶‡¶ø‡¶ï‡ßá', '‡¶¶‡¶ø‡¶§‡ßá', '‡¶¶‡¶ø‡ßü‡ßá', '‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá', '‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá‡¶®', '‡¶¶‡¶ø‡¶≤‡ßá‡¶®', '‡¶¶‡ßÅ', '‡¶¶‡ßÅ‡¶ü‡¶ø', '‡¶¶‡ßÅ‡¶ü‡ßã', '‡¶¶‡ßá‡ßü', '‡¶¶‡ßá‡¶ì‡ßü‡¶æ', '‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞', \n",
    "             '‡¶¶‡ßá‡¶ñ‡¶æ', '‡¶¶‡ßá‡¶ñ‡ßá', '‡¶¶‡ßá‡¶ñ‡¶§‡ßá', '‡¶¶‡ßç‡¶¨‡¶æ‡¶∞‡¶æ', '‡¶ß‡¶∞‡ßá', '‡¶ß‡¶∞‡¶æ', '‡¶®‡ßü', '‡¶®‡¶æ‡¶®‡¶æ', '‡¶®‡¶æ', '‡¶®‡¶æ‡¶ï‡¶ø', '‡¶®‡¶æ‡¶ó‡¶æ‡¶¶', '‡¶®‡¶ø‡¶§‡ßá', '‡¶®‡¶ø‡¶ú‡ßá', '‡¶®‡¶ø‡¶ú‡ßá‡¶á', \n",
    "             '‡¶®‡¶ø‡¶ú‡ßá‡¶∞', '‡¶®‡¶ø‡¶ú‡ßá‡¶¶‡ßá‡¶∞', '‡¶®‡¶ø‡ßü‡ßá', '‡¶®‡ßá‡¶ì‡ßü‡¶æ', '‡¶®‡ßá‡¶ì‡ßü‡¶æ‡¶∞', '‡¶®‡ßá‡¶á', '‡¶®‡¶æ‡¶á', '‡¶™‡¶ï‡ßç‡¶∑‡ßá', '‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§', '‡¶™‡¶æ‡¶ì‡ßü‡¶æ', '‡¶™‡¶æ‡¶∞‡ßá‡¶®', '‡¶™‡¶æ‡¶∞‡¶ø', '‡¶™‡¶æ‡¶∞‡ßá', \n",
    "             '‡¶™‡¶∞‡ßá', '‡¶™‡¶∞‡ßá‡¶á', '‡¶™‡¶∞‡ßá‡¶ì', '‡¶™‡¶∞', '‡¶™‡ßá‡ßü‡ßá', '‡¶™‡ßç‡¶∞‡¶§‡¶ø', '‡¶™‡ßç‡¶∞‡¶≠‡ßÉ‡¶§‡¶ø', '‡¶™‡ßç‡¶∞‡¶æ‡ßü', '‡¶´‡ßá‡¶∞', '‡¶´‡¶≤‡ßá', '‡¶´‡¶ø‡¶∞‡ßá', '‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞', '‡¶¨‡¶≤‡¶§‡ßá', \n",
    "             '‡¶¨‡¶≤‡¶≤‡ßá‡¶®', '‡¶¨‡¶≤‡ßá‡¶õ‡ßá‡¶®', '‡¶¨‡¶≤‡¶≤', '‡¶¨‡¶≤‡¶æ', '‡¶¨‡¶≤‡ßá‡¶®', '‡¶¨‡¶≤‡ßá', '‡¶¨‡¶π‡ßÅ', '‡¶¨‡¶∏‡ßá', '‡¶¨‡¶æ‡¶∞', '‡¶¨‡¶æ', '‡¶¨‡¶ø‡¶®‡¶æ', '‡¶¨‡¶∞‡¶Ç', '‡¶¨‡¶¶‡¶≤‡ßá', '‡¶¨‡¶æ‡¶¶‡ßá', \n",
    "             '‡¶¨‡¶æ‡¶∞', '‡¶¨‡¶ø‡¶∂‡ßá‡¶∑', '‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶®\t‡¶¨‡¶ø‡¶∑‡ßü‡¶ü‡¶ø', '‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞', '‡¶¨‡ßç‡¶Ø‡¶æ‡¶™‡¶æ‡¶∞‡ßá', '‡¶≠‡¶æ‡¶¨‡ßá', '‡¶≠‡¶æ‡¶¨‡ßá‡¶á', '‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá', '‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá‡¶á', '‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá‡¶ì', '‡¶Æ‡¶ß‡ßç‡¶Ø‡¶≠‡¶æ‡¶ó‡ßá', \n",
    "             '‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá', '‡¶Æ‡¶æ‡¶§‡ßç‡¶∞', '‡¶Æ‡¶§‡ßã', '‡¶Æ‡¶§‡ßã‡¶á', '‡¶Æ‡ßã‡¶ü‡ßá‡¶á', '‡¶Ø‡¶ñ‡¶®', '‡¶Ø‡¶¶‡¶ø', '‡¶Ø‡¶¶‡¶ø‡¶ì', '‡¶Ø‡¶æ‡¶¨‡ßá', '‡¶Ø‡¶æ‡ßü', '‡¶Ø‡¶æ‡¶ï‡ßá', '‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ', '‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ‡¶∞', \n",
    "             '‡¶Ø‡¶§', '‡¶Ø‡¶§‡¶ü‡¶æ', '‡¶Ø‡¶æ', '‡¶Ø‡¶æ‡¶∞', '‡¶Ø‡¶æ‡¶∞‡¶æ', '‡¶Ø‡¶æ‡¶Å‡¶∞', '‡¶Ø‡¶æ‡¶Å‡¶∞‡¶æ', '‡¶Ø‡¶æ‡¶¶‡ßá‡¶∞', '‡¶Ø‡¶æ‡¶®', '‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡ßá', '‡¶Ø‡ßá‡¶§‡ßá', '‡¶Ø‡¶æ‡¶§‡ßá', '‡¶Ø‡ßá‡¶®', '‡¶Ø‡ßá‡¶Æ‡¶®', \n",
    "             '‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá', '‡¶Ø‡¶ø‡¶®‡¶ø', '‡¶Ø‡ßá', '‡¶∞‡ßá‡¶ñ‡ßá', '‡¶∞‡¶æ‡¶ñ‡¶æ', '‡¶∞‡ßü‡ßá‡¶õ‡ßá', '‡¶∞‡¶ï‡¶Æ', '‡¶∂‡ßÅ‡¶ß‡ßÅ', '‡¶∏‡¶ô‡ßç‡¶ó‡ßá', '‡¶∏‡¶ô‡ßç‡¶ó‡ßá‡¶ì', '‡¶∏‡¶Æ‡¶∏‡ßç‡¶§', '‡¶∏‡¶¨', '‡¶∏‡¶¨‡¶æ‡¶∞', '‡¶∏‡¶π', \n",
    "             '‡¶∏‡ßÅ‡¶§‡¶∞‡¶æ‡¶Ç', '‡¶∏‡¶π‡¶ø‡¶§', '‡¶∏‡ßá‡¶á', '‡¶∏‡ßá‡¶ü‡¶æ', '‡¶∏‡ßá‡¶ü‡¶ø', '‡¶∏‡ßá‡¶ü‡¶æ‡¶á', '‡¶∏‡ßá‡¶ü‡¶æ‡¶ì', '‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶§‡¶ø', '‡¶∏‡ßá‡¶ñ‡¶æ‡¶®', '‡¶∏‡ßá‡¶ñ‡¶æ‡¶®‡ßá', '‡¶∏‡ßá', '‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü', '‡¶∏‡ßç‡¶¨‡ßü‡¶Ç', \n",
    "             '‡¶π‡¶á‡¶§‡ßá', '‡¶π‡¶á‡¶¨‡ßá', '‡¶π‡ßà‡¶≤‡ßá', '‡¶π‡¶á‡ßü‡¶æ', '‡¶π‡¶ö‡ßç‡¶õ‡ßá', '‡¶π‡¶§', '‡¶π‡¶§‡ßá', '‡¶π‡¶§‡ßá‡¶á', '‡¶π‡¶¨‡ßá', '‡¶π‡¶¨‡ßá‡¶®', '‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤', '‡¶π‡ßü‡ßá‡¶õ‡ßá', '‡¶π‡ßü‡ßá‡¶õ‡ßá‡¶®', '‡¶π‡ßü‡ßá', \n",
    "             '‡¶π‡ßü‡¶®‡¶ø', '‡¶π‡ßü', '‡¶π‡ßü‡ßá‡¶á', '‡¶π‡ßü‡¶§‡ßã', '‡¶π‡¶≤', '‡¶π‡¶≤‡ßá', '‡¶π‡¶≤‡ßá‡¶á', '‡¶π‡¶≤‡ßá‡¶ì', '‡¶π‡¶≤‡ßã', '‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá', '‡¶π‡¶ì‡ßü‡¶æ', '‡¶π‡¶ì‡ßü‡¶æ‡¶∞', '‡¶π‡¶ì‡ßü‡¶æ‡ßü', '‡¶π‡¶®', \n",
    "             '‡¶π‡ßã‡¶ï', '‡¶ú‡¶®', '‡¶ú‡¶®‡¶ï‡ßá', '‡¶ú‡¶®‡ßá‡¶∞', '‡¶ú‡¶æ‡¶®‡¶§‡ßá', '‡¶ú‡¶æ‡¶®‡¶æ‡ßü', '‡¶ú‡¶æ‡¶®‡¶ø‡ßü‡ßá', '‡¶ú‡¶æ‡¶®‡¶æ‡¶®‡ßã', '‡¶ú‡¶æ‡¶®‡¶ø‡ßü‡ßá‡¶õ‡ßá', '‡¶ú‡¶®‡ßç‡¶Ø', '‡¶ú‡¶®‡ßç‡¶Ø‡¶ì‡¶ú‡ßá', '‡¶ú‡ßá', \n",
    "             '‡¶¨‡ßá‡¶∂', '‡¶¶‡ßá‡¶®', '‡¶§‡ßÅ‡¶≤‡ßá', '‡¶õ‡¶ø‡¶≤‡ßá‡¶®', '‡¶ö‡¶æ‡¶®', '‡¶ö‡¶æ‡ßü', '‡¶ö‡ßá‡ßü‡ßá', '‡¶Æ‡ßã‡¶ü', '‡¶Ø‡¶•‡ßá‡¶∑‡ßç‡¶ü', '‡¶ü‡¶ø']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_texts(sentences):\n",
    "    # tags\n",
    "    sentences = [remove_tagging(sentence) for sentence in sentences]\n",
    "    \n",
    "    # lower case\n",
    "    sentences = [sentence.lower() for sentence in sentences]\n",
    "    \n",
    "    # remove punctuations and urls \n",
    "    sentences = [remove_punc_and_urls(sentence) for sentence in sentences]\n",
    "    \n",
    "    # substitute numbers\n",
    "    sentences = [re.sub('\\\\b[0-9]+\\\\b', substitute_number, sentence) for sentence in sentences]\n",
    "    \n",
    "    # remove stopwords\n",
    "    sentences = [[word for word in sentence.split() if word not in stopwords] for sentence in sentences]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cleaning\n",
    "\n",
    "train_sentences = clean_texts(train_sentences)\n",
    "train_texts = [' '.join(l) for l in train_sentences]\n",
    "bengali_train_df['sentence'] = train_texts\n",
    "\n",
    "test_sentences = clean_texts(test_sentences)\n",
    "test_texts = [' '.join(l) for l in test_sentences]\n",
    "bengali_test_df['sentence'] = test_texts\n",
    "\n",
    "other_sentences = clean_texts(other_sentences)\n",
    "other_texts = [' '.join(l) for l in other_sentences]\n",
    "bengali_other_df['sentence'] = other_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶∏‡¶Æ‡¶ï‡¶æ‡¶Æ‡ßÄ ‡¶π‡ßÅ‡¶ú‡ßÅ‡¶∞</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶õ‡¶æ‡¶è‡¶≤‡ßÄ‡¶ó ‡¶∏‡¶æ‡¶≤‡¶æ ‡¶¶‡ßá‡¶∞ ‡¶®‡¶ø‡¶∏‡¶ø‡¶¶‡ßç‡¶¶ ‡¶π‡¶ï</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶ï‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡¶¶‡¶ø ‡¶õ‡¶æ‡¶∞‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ú‡¶¨‡ßá ‡¶ú‡ßÅ‡¶§‡¶æ ‡¶ï‡ßá‡¶Æ‡¶®‡ßá ‡¶ñ‡¶æ‡ßü</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶ï‡¶æ‡¶â‡ßü‡¶æ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶¨‡ßú ‡¶Æ‡¶æ‡¶ó‡ßÄ‡¶ñ‡ßã‡¶∞ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶™‡¶ø‡¶ï ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ù‡¶æ ‡¶≤‡ßÅ...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶Ö‡¶™‡ßÅ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶•‡¶æ ‡¶õ‡ßã‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá‡¶®‡¶æ</td>\n",
       "      <td>0</td>\n",
       "      <td>Meme, TikTok and others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate  \\\n",
       "0                                       ‡¶∏‡¶Æ‡¶ï‡¶æ‡¶Æ‡ßÄ ‡¶π‡ßÅ‡¶ú‡ßÅ‡¶∞     0   \n",
       "1                         ‡¶õ‡¶æ‡¶è‡¶≤‡ßÄ‡¶ó ‡¶∏‡¶æ‡¶≤‡¶æ ‡¶¶‡ßá‡¶∞ ‡¶®‡¶ø‡¶∏‡¶ø‡¶¶‡ßç‡¶¶ ‡¶π‡¶ï     1   \n",
       "2               ‡¶ï‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡¶¶‡¶ø ‡¶õ‡¶æ‡¶∞‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ú‡¶¨‡ßá ‡¶ú‡ßÅ‡¶§‡¶æ ‡¶ï‡ßá‡¶Æ‡¶®‡ßá ‡¶ñ‡¶æ‡ßü     0   \n",
       "3  ‡¶ï‡¶æ‡¶â‡ßü‡¶æ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶¨‡ßú ‡¶Æ‡¶æ‡¶ó‡ßÄ‡¶ñ‡ßã‡¶∞ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶™‡¶ø‡¶ï ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶¨‡ßÅ‡¶ù‡¶æ ‡¶≤‡ßÅ...     1   \n",
       "4                            ‡¶Ö‡¶™‡ßÅ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶•‡¶æ ‡¶õ‡ßã‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá‡¶®‡¶æ     0   \n",
       "\n",
       "                  category  \n",
       "0                 religion  \n",
       "1                 politics  \n",
       "2                 politics  \n",
       "3                 politics  \n",
       "4  Meme, TikTok and others  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ‡¶ï‡ßá ‡¶∞‡¶ø‡¶Æ‡¶æ‡¶®‡¶°‡ßá</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶§‡ßÅ‡¶∞ ‡¶∞‡¶ø‡¶™‡¶æ‡¶§‡¶ï‡ßá ‡¶Æ‡¶® ‡¶ö‡¶æ‡¶á‡¶õ‡¶ø‡¶≤ ‡¶õ‡ßá‡¶°‡¶º‡ßá ‡¶ó‡ßá‡¶≤‡¶ø ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡¶ø‡¶§‡ßç‡¶Ø‡ßá ‡¶Ö...</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶π‡ßÅ‡¶Æ‡¶æ‡ßü‡ßÅ‡¶® ‡¶Ü‡¶ú‡¶æ‡¶¶ ‡¶è‡¶§‡ßã ‡¶¨‡ßú ‡¶ï‡ßç‡¶∞‡¶æ‡¶ï ‡¶Æ‡¶æ‡¶§‡¶æ‡¶≤</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶¨‡¶æ‡¶Ç‡¶æ‡¶≤ ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶∏‡¶æ‡¶π‡¶∏‡¶ø ‡¶á‡¶â‡¶ü‡ßÅ‡¶¨‡¶æ‡¶∞üëçüëçüëç</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ß‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ ‡¶ö‡ßã‡¶∞ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶´‡¶æ‡¶ü‡¶æ ‡¶ï‡ßá‡¶∑‡ßç‡¶ü ‡¶ï‡ßã‡¶á ...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate  category\n",
       "0                                    ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ‡¶ï‡ßá ‡¶∞‡¶ø‡¶Æ‡¶æ‡¶®‡¶°‡ßá     0     crime\n",
       "1  ‡¶§‡ßÅ‡¶∞ ‡¶∞‡¶ø‡¶™‡¶æ‡¶§‡¶ï‡ßá ‡¶Æ‡¶® ‡¶ö‡¶æ‡¶á‡¶õ‡¶ø‡¶≤ ‡¶õ‡ßá‡¶°‡¶º‡ßá ‡¶ó‡ßá‡¶≤‡¶ø ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡¶ø‡¶§‡ßç‡¶Ø‡ßá ‡¶Ö...     0     crime\n",
       "2                    ‡¶π‡ßÅ‡¶Æ‡¶æ‡ßü‡ßÅ‡¶® ‡¶Ü‡¶ú‡¶æ‡¶¶ ‡¶è‡¶§‡ßã ‡¶¨‡ßú ‡¶ï‡ßç‡¶∞‡¶æ‡¶ï ‡¶Æ‡¶æ‡¶§‡¶æ‡¶≤     0  religion\n",
       "3                ‡¶¨‡¶æ‡¶Ç‡¶æ‡¶≤ ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶∏‡¶æ‡¶π‡¶∏‡¶ø ‡¶á‡¶â‡¶ü‡ßÅ‡¶¨‡¶æ‡¶∞üëçüëçüëç     0  politics\n",
       "4  ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ß‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ ‡¶ö‡ßã‡¶∞ ‡¶ï‡¶æ‡¶¶‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶´‡¶æ‡¶ü‡¶æ ‡¶ï‡ßá‡¶∑‡ßç‡¶ü ‡¶ï‡ßã‡¶á ...     1  politics"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶õ‡¶¨‡¶ø‡¶ü‡¶æ ‡¶ö‡¶ñ‡ßá ‡¶™‡¶æ‡¶®‡¶ø ‡¶¨‡¶æ‡¶≤ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶õ‡¶¨‡¶ø</td>\n",
       "      <td>0</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶™‡¶æ‡¶™‡¶® ‡¶ñ‡¶æ‡¶®‡¶ï‡¶ø‡¶∞ ‡¶™‡ßã‡¶≤‡¶æ ‡¶Æ‡ßá‡¶á‡¶® ‡¶∂‡ßü‡¶§‡¶æ‡¶® ‡¶ì‡¶∞‡ßá ‡¶≤‡¶æ‡¶•‡¶•‡ßÄ ‡¶Æ‡¶æ‡¶á‡¶∞‡¶æ ‡¶¨‡¶ø...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂‡¶ü‡¶æ ‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‡¶°‡¶ø‡¶∏‡¶ø ‡¶ï‡ßá‡¶π ‡¶ó‡¶æ‡¶≤‡¶ø ‡¶°‡¶ø‡¶∏‡¶ø ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶¢‡ßá‡¶≤‡ßá...</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶á‡ßü‡¶æ ‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π ‡¶á‡¶´‡¶§‡¶æ‡¶∞‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶¶‡ßã‡ßü‡¶æ ‡¶ï‡¶¨‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶∏‡¶Æ‡ßü ‡¶¶‡ßã‡ßü...</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶Æ‡¶æ‡¶¶‡¶æ‡¶∞‡¶ö‡ßã‡¶¶ ‡¶á‡¶π‡ßÅ‡¶ß‡¶ø‡¶∞ ‡¶¶‡¶æ‡¶≤‡¶æ‡¶≤ ‡¶¨‡¶æ‡¶¨‡¶∞‡¶ø ‡¶Æ‡¶∏‡¶ú‡¶ø‡¶¶ ‡¶≠‡¶æ‡¶Ç‡¶≤‡ßá ‡¶Æ‡¶®‡ßç‡¶ß‡¶ø‡¶∞...</td>\n",
       "      <td>1</td>\n",
       "      <td>Meme, TikTok and others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate  \\\n",
       "0                        ‡¶õ‡¶¨‡¶ø‡¶ü‡¶æ ‡¶ö‡¶ñ‡ßá ‡¶™‡¶æ‡¶®‡¶ø ‡¶¨‡¶æ‡¶≤ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶õ‡¶¨‡¶ø     0   \n",
       "1  ‡¶™‡¶æ‡¶™‡¶® ‡¶ñ‡¶æ‡¶®‡¶ï‡¶ø‡¶∞ ‡¶™‡ßã‡¶≤‡¶æ ‡¶Æ‡ßá‡¶á‡¶® ‡¶∂‡ßü‡¶§‡¶æ‡¶® ‡¶ì‡¶∞‡ßá ‡¶≤‡¶æ‡¶•‡¶•‡ßÄ ‡¶Æ‡¶æ‡¶á‡¶∞‡¶æ ‡¶¨‡¶ø...     1   \n",
       "2  ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂‡¶ü‡¶æ ‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‡¶°‡¶ø‡¶∏‡¶ø ‡¶ï‡ßá‡¶π ‡¶ó‡¶æ‡¶≤‡¶ø ‡¶°‡¶ø‡¶∏‡¶ø ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶¢‡ßá‡¶≤‡ßá...     0   \n",
       "3  ‡¶á‡ßü‡¶æ ‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π ‡¶á‡¶´‡¶§‡¶æ‡¶∞‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶¶‡ßã‡ßü‡¶æ ‡¶ï‡¶¨‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶∏‡¶Æ‡ßü ‡¶¶‡ßã‡ßü...     0   \n",
       "4  ‡¶Æ‡¶æ‡¶¶‡¶æ‡¶∞‡¶ö‡ßã‡¶¶ ‡¶á‡¶π‡ßÅ‡¶ß‡¶ø‡¶∞ ‡¶¶‡¶æ‡¶≤‡¶æ‡¶≤ ‡¶¨‡¶æ‡¶¨‡¶∞‡¶ø ‡¶Æ‡¶∏‡¶ú‡¶ø‡¶¶ ‡¶≠‡¶æ‡¶Ç‡¶≤‡ßá ‡¶Æ‡¶®‡ßç‡¶ß‡¶ø‡¶∞...     1   \n",
       "\n",
       "                  category  \n",
       "0            entertainment  \n",
       "1                   sports  \n",
       "2                    crime  \n",
       "3                 religion  \n",
       "4  Meme, TikTok and others  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('train:')\n",
    "display(bengali_train_df.head())\n",
    "print('test:')\n",
    "display(bengali_test_df.head())\n",
    "print('other:')\n",
    "display(bengali_other_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab and Word <-> int transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_train_df = pd.concat([bengali_train_df, bengali_other_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 55189\n"
     ]
    }
   ],
   "source": [
    "train_sentences = [sentence.split() for sentence in bengali_train_df['sentence']]\n",
    "test_sentences = [sentence.split() for sentence in bengali_test_df['sentence']]\n",
    "embed_train_sentences = [sentence.split() for sentence in embed_train_df['sentence']]\n",
    "\n",
    "flattened_words = [word for sentence in embed_train_sentences for word in sentence]\n",
    "V = sorted(list(set(flattened_words)))\n",
    "vocab_size = len(V)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "\n",
    "word_to_int = {}\n",
    "int_to_word = {}\n",
    "for i, word in enumerate(V):\n",
    "    word_to_int[word] = i\n",
    "    int_to_word[i] = word\n",
    "\n",
    "# save dicts for transformation word <-> int\n",
    "with open('save/word_to_int_dict.json', 'w') as f:\n",
    "    json.dump(word_to_int, f)\n",
    "with open('save/int_to_word_dict.json', 'w') as f:\n",
    "    json.dump(int_to_word, f)    \n",
    "\n",
    "# save word-counter for sampling\n",
    "word_counter = Counter(flattened_words)\n",
    "with open('save/word_counter.json', 'w') as f:\n",
    "    json.dump(word_counter, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bengali_train_df.to_csv('save/bengali_hatespeech_sample_train_preprocessed.csv', index=False)\n",
    "bengali_test_df.to_csv('save/bengali_hatespeech_sample_test_preprocessed.csv', index=False)\n",
    "bengali_other_df.to_csv('save/bengali_hatespeech_other_preprocessed.csv', index=False)\n",
    "embed_train_df.to_csv('save/bengali_hatespeech_embed_train_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
