{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make embeddings for Hindilanguage\n",
    "This notebook handles the embedding process.\n",
    "\n",
    "### Input:\n",
    "    - Pre-processed training dataframe.\n",
    "\n",
    "### Output:\n",
    "    - The trained weights of the embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "import random\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(234)\n",
    "np.random.seed(345)\n",
    "random.seed(456)\n",
    "torch.manual_seed(567)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_df = pd.read_csv('save/hindi_train_preprocessed.csv')\n",
    "train_sentences = [[int(s) for s in text.split()] for text in train_df['sentence']]\n",
    "train_df['hate'] = (train_df['task_1'] == 'HOF').astype(int)\n",
    "train_labels = train_df['hate'].to_numpy()\n",
    "\n",
    "# test data\n",
    "test_df = pd.read_csv('save/hindi_test_preprocessed.csv')\n",
    "test_sentences = [[int(s) for s in text.split()] for text in test_df['sentence']]\n",
    "test_df['hate'] = (test_df['task_1'] == 'HOF').astype(int)\n",
    "test_labels = train_df['hate'].to_numpy()\n",
    "\n",
    "# word <-> convertion\n",
    "with open('save/hindi_word_to_int_dict.json', 'r') as f:\n",
    "    word_to_int = json.load(f)\n",
    "with open('save/hindi_int_to_word_dict.json', 'r') as f:\n",
    "    int_to_word = json.load(f)\n",
    "    int_to_word = {int(k) : v for k, v in int_to_word.items()}\n",
    "\n",
    "# word-counter\n",
    "with open('save/hindi_word_counter.json', 'r') as f:\n",
    "    word_counter = json.load(f)\n",
    "    \n",
    "vocab_size = len(word_to_int)\n",
    "total_words = sum(word_counter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'save/hindi_word2vec_neg.pt'\n",
    "\n",
    "window_size = 5\n",
    "embedding_size = 300\n",
    "neg_sample_factor = 10\n",
    "noise_dist_alpha = 3/4\n",
    "learning_rate = 0.01\n",
    "lr_decay = lambda epoch: max(0.03, 0.9**epoch)\n",
    "batch_size = 256\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling probability of pair (center, context)\n",
    "def sampling_prob(word):\n",
    "    z = word_counter[word] / total_words\n",
    "    p_keep = ((z/0.000001)**0.5 + 1) * (0.000001/z)\n",
    "    return p_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise distribution\n",
    "noisy_words = [iw for iw in int_to_word]\n",
    "noisy_dist = np.array([(word_counter[int_to_word[iw]]/total_words)**noise_dist_alpha for iw in noisy_words])\n",
    "noisy_dist = noisy_dist / noisy_dist.sum()\n",
    "\n",
    "# noisy word generator\n",
    "def get_noise_word(batch_size, neg_factor):\n",
    "    noise_list = np.random.choice(noisy_words, batch_size*neg_factor, p=noisy_dist)\n",
    "    noise_list = noise_list.reshape((batch_size, neg_factor))\n",
    "    return torch.from_numpy(noise_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_context(sentence: list(str())):\n",
    "    for i, word in enumerate(sentence):\n",
    "        for j, context_word in enumerate(sentence[i-window_size:i+window_size+1]):\n",
    "            if j != i and random.random() < sampling_prob(int_to_word[context_word]):\n",
    "                    yield (torch.tensor(word, dtype=torch.long), \n",
    "                           torch.tensor(context_word, dtype=torch.long)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train word-embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Word2Vec(\n",
       "  (center_embed): Embedding(19379, 300)\n",
       "  (context_embed): Embedding(19379, 300)\n",
       "  (log_sigmoid): LogSigmoid()\n",
       ")>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Word2Vec(Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.center_embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.context_embed = nn.Embedding(vocab_size, embedding_size)  \n",
    "        \n",
    "        # xavier initialization\n",
    "        init_range = (2 / (vocab_size + embedding_size)) ** 0.5\n",
    "        self.center_embed.weight.data.uniform_(-init_range, init_range)\n",
    "        self.context_embed.weight.data.uniform_(-init_range, init_range)\n",
    "        \n",
    "        self.log_sigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, center_ids, context_ids, negative_samples):\n",
    "        # center_ids, context_ids: [batch_size]\n",
    "        # negatve_samples: [batch_size, neg_sample_factor]\n",
    "        \n",
    "        # center_embed, context_embed: [batch_size, embedding_size]\n",
    "        center_embed = self.center_embed(center_ids)\n",
    "        context_embed = self.context_embed(context_ids)\n",
    "        \n",
    "        # pos_dot: [batch_size]\n",
    "        pos_dot = (center_embed * context_embed).sum(axis=1)\n",
    "        \n",
    "        # pos_loss: [batch_size]\n",
    "        pos_loss = self.log_sigmoid(pos_dot)\n",
    "        \n",
    "        # negative_embed: [batch_size, neg_sample_factor, embedding_size]\n",
    "        negative_embed = self.context_embed(negative_samples)\n",
    "        \n",
    "        # negs_dot: [batch_size, neg_sample_factor]\n",
    "        negs_dot = torch.bmm(negative_embed, center_embed.unsqueeze(2)).squeeze(2) * (-1)\n",
    "        \n",
    "        # neg_dot: [batch_size]\n",
    "        neg_dot = negs_dot.sum(axis=1)\n",
    "        \n",
    "        # neg_loss: [batch_size]\n",
    "        neg_loss = self.log_sigmoid(neg_dot)\n",
    "        \n",
    "        loss = -(pos_loss + neg_loss).sum()\n",
    "        return loss, -pos_loss.sum(), -neg_loss.sum()\n",
    "    \n",
    "    def to_embed(self, center_id):\n",
    "        return self.center_embed(center_id)\n",
    "    \n",
    "word2vec = Word2Vec()\n",
    "torch.save(word2vec.state_dict(), model_save_path)\n",
    "\n",
    "display(word2vec.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Learning-rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(word2vec.parameters(), lr=learning_rate)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2VDataset(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.data = []\n",
    "        for sentence in sentences:\n",
    "            for data_point in get_target_context(sentence):\n",
    "                self.data.append(data_point)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: training loss: 1.0749 (pos: 0.8331, neg: 0.0242) over 76758 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2: training loss: 0.9061 (pos: 0.7368, neg: 0.0169) over 76647 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3: training loss: 0.7679 (pos: 0.6047, neg: 0.0163) over 76467 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:11<00:00, 26.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4: training loss: 0.6528 (pos: 0.5145, neg: 0.0138) over 76178 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:12<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5: training loss: 0.5556 (pos: 0.4356, neg: 0.0120) over 76075 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:11<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6: training loss: 0.4835 (pos: 0.3786, neg: 0.0105) over 76480 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:09<00:00, 30.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7: training loss: 0.4102 (pos: 0.3301, neg: 0.0080) over 76492 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8: training loss: 0.3606 (pos: 0.2875, neg: 0.0073) over 76495 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9: training loss: 0.3150 (pos: 0.2536, neg: 0.0061) over 76664 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: training loss: 0.2806 (pos: 0.2274, neg: 0.0053) over 76287 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: training loss: 0.2480 (pos: 0.2017, neg: 0.0046) over 76393 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: training loss: 0.2246 (pos: 0.1826, neg: 0.0042) over 76482 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: training loss: 0.2088 (pos: 0.1697, neg: 0.0039) over 76550 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: training loss: 0.1915 (pos: 0.1545, neg: 0.0037) over 76533 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: training loss: 0.1692 (pos: 0.1386, neg: 0.0031) over 76268 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: training loss: 0.1659 (pos: 0.1344, neg: 0.0031) over 76450 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: training loss: 0.1523 (pos: 0.1245, neg: 0.0028) over 76294 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: training loss: 0.1442 (pos: 0.1167, neg: 0.0028) over 76154 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: training loss: 0.1390 (pos: 0.1123, neg: 0.0027) over 76072 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: training loss: 0.1278 (pos: 0.1041, neg: 0.0024) over 76086 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: training loss: 0.1225 (pos: 0.0986, neg: 0.0024) over 76418 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: training loss: 0.1170 (pos: 0.0941, neg: 0.0023) over 76401 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: training loss: 0.1133 (pos: 0.0905, neg: 0.0023) over 76066 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: training loss: 0.1087 (pos: 0.0877, neg: 0.0021) over 76659 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: training loss: 0.1057 (pos: 0.0845, neg: 0.0021) over 76788 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss: 0.0997 (pos: 0.0798, neg: 0.0020) over 76364 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:10<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: training loss: 0.1028 (pos: 0.0807, neg: 0.0022) over 75989 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: training loss: 0.0985 (pos: 0.0781, neg: 0.0020) over 76230 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: training loss: 0.0945 (pos: 0.0755, neg: 0.0019) over 76148 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: training loss: 0.0896 (pos: 0.0733, neg: 0.0016) over 76355 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: training loss: 0.0894 (pos: 0.0715, neg: 0.0018) over 76745 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: training loss: 0.0915 (pos: 0.0734, neg: 0.0018) over 76315 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: training loss: 0.0865 (pos: 0.0701, neg: 0.0016) over 76603 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: training loss: 0.0826 (pos: 0.0650, neg: 0.0018) over 76570 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: training loss: 0.0852 (pos: 0.0667, neg: 0.0019) over 76378 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: training loss: 0.0841 (pos: 0.0660, neg: 0.0018) over 76503 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: training loss: 0.0838 (pos: 0.0657, neg: 0.0018) over 76599 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: training loss: 0.0809 (pos: 0.0632, neg: 0.0018) over 76228 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: training loss: 0.0832 (pos: 0.0648, neg: 0.0018) over 76228 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:10<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: training loss: 0.0824 (pos: 0.0641, neg: 0.0018) over 76093 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: training loss: 0.0807 (pos: 0.0635, neg: 0.0017) over 76325 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:10<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: training loss: 0.0809 (pos: 0.0631, neg: 0.0018) over 75987 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:10<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: training loss: 0.0798 (pos: 0.0606, neg: 0.0019) over 75993 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: training loss: 0.0785 (pos: 0.0615, neg: 0.0017) over 76385 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: training loss: 0.0763 (pos: 0.0597, neg: 0.0017) over 76798 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:09<00:00, 30.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: training loss: 0.0756 (pos: 0.0602, neg: 0.0015) over 76132 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:09<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: training loss: 0.0750 (pos: 0.0590, neg: 0.0016) over 76477 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:09<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: training loss: 0.0724 (pos: 0.0564, neg: 0.0016) over 76762 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:10<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: training loss: 0.0710 (pos: 0.0555, neg: 0.0015) over 75785 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:11<00:00, 25.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: training loss: 0.0735 (pos: 0.0575, neg: 0.0016) over 76047 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 29.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss: 0.0725 (pos: 0.0557, neg: 0.0017) over 76463 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:11<00:00, 26.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: training loss: 0.0697 (pos: 0.0541, neg: 0.0016) over 76199 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: training loss: 0.0716 (pos: 0.0552, neg: 0.0016) over 76501 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:10<00:00, 28.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: training loss: 0.0701 (pos: 0.0540, neg: 0.0016) over 75875 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:10<00:00, 28.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: training loss: 0.0700 (pos: 0.0532, neg: 0.0017) over 76290 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:11<00:00, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: training loss: 0.0698 (pos: 0.0531, neg: 0.0017) over 75916 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:12<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: training loss: 0.0679 (pos: 0.0518, neg: 0.0016) over 76144 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:11<00:00, 25.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: training loss: 0.0658 (pos: 0.0503, neg: 0.0016) over 76276 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:11<00:00, 27.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: training loss: 0.0653 (pos: 0.0491, neg: 0.0016) over 76420 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:11<00:00, 26.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: training loss: 0.0655 (pos: 0.0510, neg: 0.0014) over 76100 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:11<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: training loss: 0.0660 (pos: 0.0504, neg: 0.0016) over 76394 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:12<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: training loss: 0.0649 (pos: 0.0488, neg: 0.0016) over 76263 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:13<00:00, 23.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: training loss: 0.0642 (pos: 0.0498, neg: 0.0014) over 76795 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:12<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: training loss: 0.0620 (pos: 0.0484, neg: 0.0014) over 76252 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [00:11<00:00, 26.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: training loss: 0.0639 (pos: 0.0481, neg: 0.0016) over 76272 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:10<00:00, 28.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: training loss: 0.0626 (pos: 0.0467, neg: 0.0016) over 75972 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:11<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: training loss: 0.0623 (pos: 0.0475, neg: 0.0015) over 76373 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:12<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: training loss: 0.0626 (pos: 0.0466, neg: 0.0016) over 76593 training points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:12<00:00, 24.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: training loss: 0.0631 (pos: 0.0466, neg: 0.0017) over 76386 training points.\n",
      "Early stopping: training loss does not decrease after 5 epochs\n",
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load initial weights\n",
    "word2vec.load_state_dict(torch.load(model_save_path, map_location=torch.device(device)))\n",
    "word2vec = word2vec.to(device)\n",
    "\n",
    "early_stop = 5\n",
    "history_losses = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_dataset = W2VDataset(train_sentences)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    losses, pos_losses, neg_losses = 0., 0., 0.\n",
    "    cnt = 0\n",
    "    \n",
    "    word2vec.train()\n",
    "    for center_words, context_words in tqdm(train_loader):\n",
    "        negative_samples = get_noise_word(len(center_words), neg_sample_factor)\n",
    "        optimizer.zero_grad()\n",
    "        loss, pos_loss, neg_loss = word2vec(center_words.to(device), context_words.to(device), negative_samples.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss\n",
    "        cnt += len(center_words)\n",
    "        pos_losses += pos_loss\n",
    "        neg_losses += neg_loss\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_loss = losses / cnt\n",
    "    print(f'Epoch {epoch:2}: training loss: {epoch_loss:.4f} (pos: {pos_losses/cnt:.4f}, neg: {neg_losses/(cnt*neg_sample_factor):.4f}) over {cnt} training points.')\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        # save embedding\n",
    "        embedding_weights = word2vec.center_embed.state_dict()\n",
    "        torch.save(embedding_weights, f'save/hindi_embeddings/{epoch}_epoch_{embedding_size}_dim_{window_size}_wsize_{neg_sample_factor}_negfac.pt')\n",
    "    \n",
    "    history_losses.append(epoch_loss)\n",
    "    if len(history_losses) > early_stop and min(history_losses[-early_stop:]) >= min(history_losses[:-early_stop]):\n",
    "        print(f'Early stopping: training loss does not decrease after {early_stop} epochs')\n",
    "        break\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedding weights\n",
    "embedding_weights = word2vec.center_embed.state_dict()\n",
    "torch.save(embedding_weights, f'save/hindi_embedding_weights_{window_size}_wsize_{neg_sample_factor}_negfac.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
