=== NNTI Project ===

Task 3: ---

1 March: commit a09f90a3d91e6932055818a80abf3febcb94b96c
	+) Implement all needed code for Task 1 and Task 2
	+) The code needs to be cleaned before submitting:
		-) don't run the test-data evaluation after every epoch
		-) limit epochs to 5?
		-) etc.
	+) Task 2 (Bengali) accuracy is currently 0.7867

2 March: commit 079a5a5750c71d56c773e9f4b671023faf332e68
	+) Create baseline for task 3 Bengali: accuracy 0.8-0.81


3 March: commit 75ae27b80e182594f69f5b96fec14b8902ee6aae
	+) Preprocess: 
		- Form phrases of 2 grams (threshold: appear >= 10 times in train data)
			-> Seems not really effective. Maybe because the data is small so the statistical inference 
			is not reliable.

	+) Embeddings: 
		- Use adaptive learning rate
		- Use window_size = 3, 5, 10: test acc doesn't really change
		- Use the embedding 10 epochs or 30 epochs doesn't make a real difference in accuracy

	+) Classify:
		- Batch size: change from 32 to 64 makes the accuracy curve smoother

3 March: commit ca292d7083543976ace8ed22cb9095ce2da0f75f
	+) Embeddings:
		- Use Negative Sampling with suggested parameters from the paper:
			.Use logistic regression to classify locality.
			.2 different embedding matrices for center and context words.
			.The proportion of negative samples is 10 (5-20 for small dataset)
			.Noise distribution is (U(w)/Z)^(3/4)
			-> Accuracy is worse than using basic skip-gram, only around 0.78-0.79.

4 March commit 88c144075a6dec6207174013197288af008ddef8
	+) Embeddings: 
		- Modify Negative Sampling to make it more formal.
		- Follow the lost function in paper.
		- Speed up.
		-> accuracy is increased to 0.82.

4 March commit 054497d98b837827c4b6be9ab7af150ad739f35b
	+) Preprocess:
		- substitute numbers: keep 0, 1, 2 and substitute all other numbers to ..._digits_number
	+) Embeddings:
		- Use Xavier initialization as we are using Sigmoid activation.
		-> faster convergence

5 March commit 5626f7496d92c81860aa746e9da711353d293821
	+) Embeddings:
		- try varying neg_sample_factor to 2/5/10/20/100.
		-> 5 tends to give better accuracy. Note that this is not very intuitive.
	+) Classify:
		- try using Xavier but there is no real change.

7 March commit 039f2cc0cd38d2c6ccc6df8e5da0dcb19632f09f
	+) Embeddings:
		- Try using GloVe.
		-> result is not good, roundly 0.77-0.78. This might be because the statistical inference
		in this very-small-dataset is not effective. This is similar to the case of trying 2-grams.

7 March commit 92a25349315bcc00f27c7dfb2ab1f43311f0e7df
	+) Task 1: 
		- Change window_size to 10
		- make submission-ready

8 March commit d202ccdb2ab84ae08680a4423d845f39d955e041
	+) Task 2:
		- make submission-ready

Current Accuracy:
	+ hindi - hindi: 0.6115
	+ hindi - bengali: 0.7388
	+ bengali - bengali: 0.7952

9 March commit 3dbb0d2
	Task 3 hindi-hindi:
	+) Preprocess:
		- use 2grams with >= 12 occurences
		-> accuracy is reduced by ~ 1%
		- remove urls
		-> don't really change accuracy?
		- substitute numbers
		-> accuracy + 1%

	+) Embeddings:
		- Adjust the sampling_prob()
		- learning rate init from 0.005 to 0.01
	+) Classify:
		- Use 2 Attention layers, increase dropout to 0.7, #heads: [10, 5]
		- learning_rate: from 1e-4 to 5e-5
	
	-> accuracy is ~ 0.8-0.81

9 March commit af74a81
	Task 3 hindi-hindi:
	+) Classify:
		- Try with and without att mask
		-> accuracy doesn't really change
		- Add sin-cos positional encoding
		-> the accuracy increases a bit, furthermore, accuracy doesn't decrease as model overfits.

9 March commit 67101f1
	Task 3 hindi-hindi:
	+) Classify:
		- Make a separated Encoder (and EncoderEssential) class
		- Fix, use Layer norm instead of wrongly used InstanceNorm
		- add Batch statistics

9 March commit fb2c96b
	Task 3 hindi-hindi:
	+) Classify:
		- use plotly for batch statistics.

9 March commit c5b189e
	Task 3 hindi-hindi:
	+) Embedding:
		- try window_size=10
		-> seems like the accuracy is smaller, roundly 79-80%

9 March commit c137b6f
	Task 3 hindi-hindi:
	+) Embedding:
		- try window_size=3
		-> seems like the accuracy is smaller, roundly 78-79%


11 March commit
	Task 3: get all ready
	+) Embedding:
		- Use whole dataset (exlucding test set) for embedding.
		-> acc increase 1-1.5% to 82.5-83%

======== Switch to new Repo ========

11 March commit 2bdf461
	get everything ready
	

11 March commit fe1baa1
	Task 3 hindi-hindi and bengali-bengali:
	+) Classify:
		Try augmentation by removing some words from sentences (with mild prob e.g. 0.1 to 0.3)
		-> the accuracy is a bit ridge and a bit lower

12 March commit 5a1acdf
	Task 3 hindi-hindi and bengali-bengali:
	+) Classify:
		Try augmentation by substituting some words with their synonyms
		-> the accuracy is also a bit lower

12 March commit
	Task 3 hindi-hindi and bengali-bengali:
	+) Classify:
		Try repeating the sentence (as in Note 11 below).
		-> don't see improvement.


-----------

Note:
y 1. If there is @hindi-name?
	Try to print all words containing "@" but there seems to be no such case
y 2. Transformer, MultiHeadAttention
x 3. Take randomly a value of the output as the prediction
o 4. Prevent model from being very sure
o 5. Allow phrase, not just word
o 6. Use overleaf
y 7. Work log
o 8. Use Weight multiplicative to sample from training data.
o 9. Learning Rate Finder (2015).
o 10. 8 pages of the report not count the reference.
o 11. When reading a long sentence/paragraph, we often need to re-read it one more time to grasp its content. May use this in LSTM.
y 12. Remove number
o 13. Sampling should also be based on distance between center word and context word.
y 14. Add feed-forward, shortcut, more encoder layers
y 15. Negative sampling
y 16. Initialization (e.g. Xavier init: https://github.com/blackredscarf/pytorch-SkipGram/blob/master/model.py)
o 17. Dense-Sparse-Dense
x 18. Explore: Transfer -> Hindi - Bengali translation
o 19. In transfer learning, try both fix/not fix non-embedding layers.
x 20. Training augmentation by removing words.
x 21. Instance Norm
x 22. Augmentation by replacing with synonym.
o 23. Test-time augmentation.


Difficulty/Problems:
	- Unknown languages, both Hindi and Bengali.
	- Small data size. Only <4700 observations in Hindi, much smaller than the dataset in original paper.
	- Reproducibility: by far it seems that there is no way to make training deterministic over multiple runs.


Questions:
1. 1 report for all tasks? Yes
2. Bengali, words are separated by space (just like in English), right? it has 50k
3. In task 2, should we use the embedding from task 1 to embed Bengali words? or we just use the same model architecture to train the embedding on Bengali words? Hindi and Bengali has the same vocabulary?
4. Points distribution for task 2 and 3: results mean accuracy? how much accuracy is considered enough, quantitatively?


References:
- Understanding the difficulty of training deep feedforward neural networks, Glorot and Bengio, http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf?hc_location=ufi] -> Xavier initialization and how it works well for tanh and sigmoid activation. It helps ensure the variance of the input and output are equal, which avoids gradient vanishing/exploding and makes training more efficient.
- Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification, He et al., https://arxiv.org/abs/1502.01852 -> He initialization for ReLU activation.
- On weight initialization in deep neural networks, Kumar, https://arxiv.org/abs/1704.08863 -> prove He initialization, show why Xavier initialization does not work for ReLU